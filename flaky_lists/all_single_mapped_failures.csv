project,module,testName,exceptionType,errorMessage
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.gateway.EventBasedGatewayTest.testCatchTimerCancelsSignal,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.event.error.ErrorEventSubProcessTest.testErrorCodeTakesPrecedence,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.async.AsyncTaskTest.testAsyncEndEvent,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.cCreateStandaloneTaskForGroupAndClaim,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeClaimReleaseTest.aCreateStandaloneTaskForGroup,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.aCreateStandaloneTaskAndComplete,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.aCreateStandaloneTaskForAnotherAssignee,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.bCreateCheckTaskCreatedForSalaboyFromAnotherUser,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeClaimReleaseTest.fCreateStandaloneTaskAndClaimAndReleaseUnAuthorized,java.lang.Exception,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeDeleteTaskTest.aCreateStandaloneTaskAndDelete,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeUnAuthorizedTest.bClaimNotFoundBecauseYouAreNotACandidate,java.lang.Exception, Unexpected exception; expected<org.activiti.api.runtime.shared.NotFoundException> but was<org.activiti.engine.ActivitiIllegalArgumentException>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.ctryCompletingWithUnauthorizedUser,java.lang.Exception, Unexpected exception; expected<org.activiti.api.runtime.shared.NotFoundException> but was<org.activiti.engine.ActivitiIllegalArgumentException>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.bCreateStandaloneTask,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskForOtherTest.aCreateStandaloneTaskWithNoCandidates,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeStandaloneTaskTest.bCreateStandaloneTaskForGroup,java.lang.AssertionError,* Multiple error messages. *
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.internal.schedule.JobRegistryTest.assertGetCurrentShardingTotalCountIfNull,java.lang.AssertionError, \\nExpected: is <0>\\n     but: was <10>\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.reg.zookeeper.ZookeeperRegistryCenterModifyTest.assertPersistEphemeralSequential,java.lang.AssertionError, \\nExpected: is <2>\\n     but: was <4>\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-lifecycle,io.elasticjob.lite.lifecycle.api.JobAPIFactoryTest.assertCreateServerStatisticsAPI,io.elasticjob.lite.reg.exception.RegException, java.net.BindException: Address already in use\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-lifecycle,io.elasticjob.lite.reg.zookeeper.ZookeeperRegistryCenterModifyTest.assertPersistEphemeralSequential,io.elasticjob.lite.reg.exception.RegException, java.net.BindException: Address already in use\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-spring,io.elasticjob.lite.spring.job.JobSpringNamespaceWithListenerAndJdkDynamicProxyTest.assertSpringJobBean,io.elasticjob.lite.reg.exception.RegException, java.net.BindException: Address already in use\\n
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.gateway.EventBasedGatewayTest.testCatchTimerCancelsSignal,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.event.error.ErrorEventSubProcessTest.testErrorCodeTakesPrecedence,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.async.AsyncTaskTest.testAsyncEndEvent,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeClaimReleaseTest.eCreateStandaloneTaskAndClaimAndReleaseUnAuthorized,org.activiti.engine.ActivitiIllegalArgumentException, Task id is null\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeDeleteTaskTest.aCreateStandaloneTaskAndDelete,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeClaimReleaseTest.aCreateStandaloneTaskForGroup,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.aCreateStandaloneTaskForAnotherAssignee,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeUnAuthorizedTest.bClaimNotFoundBecauseYouAreNotACandidate,java.lang.Exception, Unexpected exception; expected<org.activiti.api.runtime.shared.NotFoundException> but was<org.activiti.engine.ActivitiIllegalArgumentException>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeClaimReleaseTest.fCreateStandaloneTaskAndClaimAndReleaseUnAuthorized,java.lang.Exception, Unexpected exception; expected<org.activiti.api.runtime.shared.NotFoundException> but was<org.activiti.engine.ActivitiIllegalArgumentException>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskForOtherTest.aCreateStandaloneTaskWithNoCandidates,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.bCreateCheckTaskCreatedForSalaboyFromAnotherUser,java.lang.AssertionError, \\nExpected size:<1> but was:<0> in:\\n<[]>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeUnAuthorizedTest.aCreateStandaloneTaskForGroup,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeDeleteTaskTest.eClaimTaskCreatedForGroup,java.lang.Exception, Unexpected exception; expected<org.activiti.api.runtime.shared.NotFoundException> but was<org.activiti.engine.ActivitiIllegalArgumentException>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeDeleteTaskTest.dClaimTaskCreatedForGroup,org.activiti.engine.ActivitiIllegalArgumentException, Task id is null\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeDeleteTaskTest.cCreateStandaloneGroupTaskClaimAndDeleteFail,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.ctryCompletingWithUnauthorizedUser,java.lang.Exception, Unexpected exception; expected<org.activiti.api.runtime.shared.NotFoundException> but was<org.activiti.engine.ActivitiIllegalArgumentException>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskForOtherTest.bCheckThatTaskIsNotVisibleForNonCandidateUsers,java.lang.AssertionError, \\nExpected size:<0> but was:<2> in:\\n<[TaskImpl{id='482a1e23-cecc-11e8-a943-0242ac110002'; owner='garth'; assignee='null'; name='group task'; description='null'; createdDate=Sat Oct 13 09:42:21 UTC 2018; claimedDate=null; dueDate=null; priority=0; processDefinitionId='null'; processInstanceId='null'; parentTaskId='null'; status=CREATED};\\n    TaskImpl{id='4832a9a6-cecc-11e8-a943-0242ac110002'; owner='garth'; assignee='null'; name='group task'; description='null'; createdDate=Sat Oct 13 09:42:21 UTC 2018; claimedDate=null; dueDate=null; priority=0; processDefinitionId='null'; processInstanceId='null'; parentTaskId='null'; status=CREATED}]>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.bCreateStandaloneTask,java.lang.AssertionError, \\nExpected size:<1> but was:<2> in:\\n<[TaskImpl{id='4b68f59a-cecc-11e8-a943-0242ac110002'; owner='garth'; assignee='null'; name='simple task'; description='null'; createdDate=Sat Oct 13 09:42:26 UTC 2018; claimedDate=null; dueDate=null; priority=0; processDefinitionId='null'; processInstanceId='null'; parentTaskId='null'; status=CREATED};\\n    TaskImpl{id='4b6e73dd-cecc-11e8-a943-0242ac110002'; owner='garth'; assignee='garth'; name='simple task'; description='null'; createdDate=Sat Oct 13 09:42:26 UTC 2018; claimedDate=null; dueDate=null; priority=0; processDefinitionId='null'; processInstanceId='null'; parentTaskId='null'; status=ASSIGNED}]>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.aCreateStandaloneTaskAndComplete,java.lang.AssertionError,* Multiple error messages. *
alibaba.fastjson,fastjson-,com.alibaba.json.bvt.serializer.date.DateTest4_indian.test_date,junit.framework.AssertionFailedError, expected:<17100000> but was:<45900000>\\n
apache.hadoop,hadoop-hadoop-common-project-hadoop-auth,org.apache.hadoop.security.authentication.util.TestKerberosName.testRules,KeeperException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.fileSystemCache,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.fileSystemExecutor,org.apache.hadoop.lib.service.FileSystemAccessException, H03: FileSystemExecutor error; org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.servlet.TestServerWebApp.getHomeDirNotDef,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.test.TestHFSTestCase.testHadoopFileSystem,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.createFileSystem,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testAllowSnapshot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testGetTrashRoot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testFileAcls,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testGetTrashRoot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.instrumentation,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testPerms,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterShutDownJob,java.lang.AssertionError, Expected shutDownJob to exit with status code of 0. expected:<0> but was:<1>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher.testSlowNM,org.apache.hadoop.yarn.exceptions.YarnRuntimeException, could not cleanup test dir\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRename,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsinfo,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testSetattr,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testPathconf,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCreate,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRead,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRmdir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddirplus,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReadlink,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCommit,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testMkdir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRemove,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testAccess,java.lang.AssertionError, Incorrect return code expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testSymlink,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsRenameSingleNN,java.lang.AssertionError, expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testLookup,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testGetattr,java.lang.AssertionError, Incorrect return code expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsstat,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testWrite,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testWrongNfsAccess,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRemove,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testAccess,java.lang.AssertionError, Incorrect return code expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRename,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsinfo,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsRenameSingleNN,java.lang.AssertionError, expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testLookup,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testSetattr,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testPathconf,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCreate,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCommit,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsstat,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testWrongNfsAccess,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.fs.http.server.TestHttpFSServer.testAllowSnapshot,java.lang.InterruptedException, sleep interrupted\\n08:44:23;822  INFO Server:621 - Services destroyed\\n08:44:23;822  INFO Server:633 - Server [httpfs] shutdown!\\n08:44:23;822  INFO Server:634 - ======================================================\\njava.io.FileNotFoundException: File does not exist: /tmp/tmp-snap-allow-test\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapred.TestJobEndNotifier.testNotificationTimeout,java.lang.AssertionError,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenEnabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenEnabled,java.lang.ExceptionInInitializerError,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-registry,org.apache.hadoop.registry.secure.TestSecureLogins.testUGILogin,org.apache.hadoop.security.KerberosAuthException, failure to login: for principal: zookeeper from keytab /home/colossus2/apache/hadoop/target/kdc/zookeeper.keytab javax.security.auth.login.LoginException: Integrity check on decrypted field failed (31) - PREAUTH_FAILED\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-router,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError, expected:<500> but was:<400>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError, expected:<500> but was:<404>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenEnabled,java.lang.ExceptionInInitializerError,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.registry.client.impl.TestCuratorService.testRM,org.apache.hadoop.fs.PathIsNotEmptyDirectoryException, `/registry/rm': Directory is not empty: KeeperErrorCode = Directory not empty for /registry/rm\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRename,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsRenameSingleNN,java.lang.AssertionError, expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testPathconf,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testWrongNfsAccess,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testGetEntityPluginRead,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testMoveToDone,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testParseSummaryLogs,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testGetattr,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testAccess,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCreate,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testSymlink,java.io.IOException, Timed out waiting for Mini HDFS Cluster to start\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRead,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddir,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRmdir,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReadlink,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddirplus,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsinfo,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCommit,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testWrite,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testMkdir,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestLogInfo.testParseBrokenEntity,org.apache.hadoop.hdfs.server.common.InconsistentFSStateException, Directory /home/colossus2/apache/hadoop/target/test/data/dfs/name-0-1 is in an inconsistent state: storage directory does not exist or is not accessible.\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestExportsTable.testViewFsMultipleExportPoint,java.io.IOException, renameTo(src=/home/colossus2/apache/hadoop/target/test/data/dfs/name-0-1/current/seen_txid.tmp; dst=/home/colossus2/apache/hadoop/target/test/data/dfs/name-0-1/current/seen_txid) failed.\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.fs.http.server.TestHttpFSServer.testAllowSnapshot,java.lang.InterruptedException, sleep interrupted\\n09:29:12;902  INFO Server:621 - Services destroyed\\n09:29:12;902  INFO Server:633 - Server [httpfs] shutdown!\\n09:29:12;902  INFO Server:634 - ======================================================\\njava.io.FileNotFoundException: File does not exist: /tmp/tmp-snap-allow-test\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.fs.http.server.TestHttpFSServer.testGetTrashRoot,java.lang.InterruptedException, sleep interrupted\\n09:29:10;533  INFO Server:621 - Services destroyed\\n09:29:10;533  INFO Server:633 - Server [httpfs] shutdown!\\n09:29:10;533  INFO Server:634 - ======================================================\\norg.junit.ComparisonFailure: expected:</[user/user1]/.Trash> but was:</[home/colossus2]/.Trash>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.fs.http.server.TestHttpFSServer.testPerms,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenEnabled,java.lang.ExceptionInInitializerError,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.lib.servlet.TestServerWebApp.getHomeDirNotDef,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.fs.http.server.TestHttpFSServer.testAllowSnapshot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.fs.http.server.TestHttpFSServer.testGetTrashRoot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.fileSystemCache,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.fileSystemExecutor,org.apache.hadoop.lib.service.FileSystemAccessException, H03: FileSystemExecutor error; org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.lib.servlet.TestServerWebApp.getHomeDirNotDef,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.test.TestHFSTestCase.testHadoopFileSystem,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.createFileSystem,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hbase,hbase-hbase-zookeeper,org.apache.hadoop.hbase.zookeeper.TestInstancePending.test,java.lang.InterruptedException, sleep interrupted\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-all,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-all,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-bom,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-bootstrap,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-cluster,org.apache.dubbo.rpc.cluster.support.ForkingClusterInvokerTest.testClearRpcContext,java.lang.AssertionError, set attachment failed!\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-cluster,org.apache.dubbo.rpc.cluster.StickyTest.testStickyNoCheck,java.lang.AssertionError,
apache.incubator-dubbo,incubator-dubbo-dubbo-cluster,org.apache.dubbo.rpc.cluster.StickyTest.testMethodStickyNoCheck,java.lang.AssertionError,
apache.incubator-dubbo,incubator-dubbo-dubbo-common,org.apache.dubbo.common.threadlocal.InternalThreadLocalTest.testSize,java.lang.AssertionError, size method is wrong!\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-compatible,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-compatible,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.AbstractInterfaceConfigTest.testLoadRegistries,java.lang.IllegalStateException, the temporary folder has not yet been created\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.AbstractInterfaceConfigTest.testListener,java.lang.IllegalStateException, the temporary folder has not yet been created\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.ReferenceConfigTest.testInjvm,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.validation.ValidationTest.testGenericValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.validation.ValidationTest.testProviderValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.ReferenceConfigTest.testInjvm,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.AbstractInterfaceConfigTest.testListener,java.lang.IllegalStateException, the temporary folder has not yet been created\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.validation.ValidationTest.testGenericValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.validation.ValidationTest.testProviderValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.validation.ValidationTest.testValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.spring.beans.factory.annotation.ServiceAnnotationBeanPostProcessorTest.test,java.lang.IllegalStateException, Failed to load ApplicationContext\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-container-dubbo-container-logback,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-container-dubbo-container-logback,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-container-dubbo-container-logback,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-container-dubbo-container-spring,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-container-dubbo-container-spring,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-container-dubbo-container-spring,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-filter-dubbo-filter-cache,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-monitor-dubbo-monitor-default,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-monitor-dubbo-monitor-default,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-monitor-dubbo-monitor-default,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-monitor-dubbo-monitor-default,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-plugin,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-plugin-dubbo-qos,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-plugin-dubbo-qos,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-plugin-dubbo-qos,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-plugin-dubbo-qos,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-default,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-default,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-default,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-default,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-multicast,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-redis,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-redis,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-redis,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-zookeeper,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-zookeeper,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-zookeeper,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-zookeeper,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-http,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-http,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-http,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-http,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-mina,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-mina,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-mina,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-mina,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-netty,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-netty,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-netty,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-netty,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-netty,org.apache.dubbo.remoting.exchange.support.header.HeartbeatHandlerTest.testHeartbeat,java.lang.AssertionError,
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-netty4,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-p2p,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-p2p,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-p2p,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-p2p,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-zookeeper,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-zookeeper,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-zookeeper,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-remoting-dubbo-remoting-zookeeper,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-api,org.apache.dubbo.rpc.proxy.jdk.JdkProxyFactoryTest.testGetInvoker,java.lang.AssertionError,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-api,org.apache.dubbo.rpc.proxy.javassist.JavassistProxyFactoryTest.testGetInvoker,java.lang.AssertionError, expected:<java.lang.Object@453da22c> but was:<aa>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-dubbo,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-dubbo,org.apache.dubbo.rpc.protocol.dubbo.DubboProtocolTest.testDubboProtocolWithMina,org.apache.dubbo.rpc.RpcException, Unsupported server type: mina; url: dubbo://127.0.0.1:9010/org.apache.dubbo.rpc.protocol.dubbo.support.DemoService?channel.readonly.sent=true&heartbeat=60000&server=mina\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-dubbo,org.apache.dubbo.rpc.protocol.dubbo.telnet.ListTelnetHandlerTest.testListService,org.apache.dubbo.rpc.RpcException, Fail to start server(url: dubbo://127.0.0.1:20885/demo?channel.readonly.sent=true&codec=dubbo&heartbeat=60000) Failed to bind NettyServer on /127.0.0.1:20885; cause: Address already in use\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-dubbo,org.apache.dubbo.rpc.protocol.dubbo.telnet.ListTelnetHandlerTest.testList,org.apache.dubbo.rpc.RpcException, Fail to start server(url: dubbo://127.0.0.1:20885/demo?channel.readonly.sent=true&codec=dubbo&heartbeat=60000) Failed to bind NettyServer on /127.0.0.1:20885; cause: Address already in use\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-hessian,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-hessian,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-hessian,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-hessian,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-http,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-http,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-http,org.apache.dubbo.rpc.protocol.http.HttpProtocolTest.testTimeOut,java.lang.IllegalStateException, Failed to start jetty server on null:null; cause: Address already in use\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-http,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-http,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-http,org.apache.dubbo.rpc.protocol.http.HttpProtocolTest.testGenericInvokeWithNativeJava,java.lang.IllegalStateException, Failed to start jetty server on null:null; cause: Address already in use\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-redis,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-redis,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-redis,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-redis,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-rest,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-rest,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-rest,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-rest,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-rmi,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-rmi,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-rmi,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-rmi,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-thrift,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-thrift,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-thrift,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-webservice,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-webservice,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-webservice,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-webservice,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-fastjson,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-fastjson,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-fst,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-fst,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-fst,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-fst,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-jdk,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-jdk,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-jdk,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-kryo,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-kryo,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-kryo,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-test,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-core,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.singleQueryRun,java.lang.AssertionError, expected:<1> but was:<0>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-core,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.multipleQueryRuns,java.lang.AssertionError, \\nExpected: is <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n     but: was <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-jcr,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.singleQueryRun,java.lang.AssertionError, expected:<1> but was:<0>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-jcr,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.multipleQueryRuns,java.lang.AssertionError, \\nExpected: is <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n     but: was <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-segment-tar,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.multipleQueryRuns,java.lang.AssertionError, \\nExpected: is <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n     but: was <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr286DispatcherTest.testRender_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr286DispatcherTest.testProcessAction_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr168DispatcherTest.testRender_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr168DispatcherTest.testProcessAction_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
crawlscript.webcollector,WebCollector-,cn.edu.hfut.dmic.webcollector.util.OkHttpRequesterTest.testHttpCode,java.lang.AssertionError, java.net.SocketTimeoutException: connect timed out\\n
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_full_collection_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_collection_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_map_key_value,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_map_key_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_index_and_multi_clustering_columns_slice,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_map_key_entry,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_index_and_clustering_column,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_index_and_clustering_column_slice,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.bugs.TestEntityWithCaseSensitivePKIT.should_dsl_select_with_token_value,java.lang.AssertionError, \\nExpecting actual not to be null\\n
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_simple_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_map_key_value_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_collection_index_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_map_key_index_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_full_collection_index_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_map_key_entry_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_10,info.archinnov.achilles.it.TestEntityForGroupByIT.should_select_sum_group_by_partition_keys_and_one_clustering,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_10,info.archinnov.achilles.it.TestEntityForGroupByIT.should_select_sum_group_by_partition_keys,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_eq_non_tokenizer,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_like_non_tokenizer,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_contains,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_like,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_prefix_non_tokenizer,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_end_with,java.lang.AssertionError, \\nExpected size:<1> but was:<6> in:\\n<[info.archinnov.achilles.internals.entities.EntityWithSASIIndices@3c9bfddc; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@1a9c38eb; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@319bc845; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@4c5474f5; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@2f4205be; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@54e22bdd]>\\n
dropwizard.dropwizard,dropwizard-dropwizard-e2e,com.example.app1.App1Test.customJsonProviderRoundtrip,java.lang.NullPointerException,
dropwizard.dropwizard,dropwizard-dropwizard-e2e,com.example.app1.App1Test.customJsonProvider,java.lang.NullPointerException,
dropwizard.dropwizard,dropwizard-dropwizard-e2e,com.example.app1.App1Test.customJsonProviderClient,java.lang.NullPointerException,
dropwizard.dropwizard,dropwizard-dropwizard-logging,io.dropwizard.logging.DefaultLoggingFactoryPrintErrorMessagesTest.testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut,java.lang.AssertionError,* Multiple error messages. *
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.reg.zookeeper.ZookeeperRegistryCenterModifyTest.assertPersistEphemeralSequential,java.lang.AssertionError, \\nExpected: is <2>\\n     but: was <4>\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.internal.schedule.JobRegistryTest.assertGetCurrentShardingTotalCountIfNull,java.lang.AssertionError, \\nExpected: is <0>\\n     but: was <10>\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.event.rdb.JobEventRdbSearchTest.assertFindJobStatusTraceEventsWithTime,java.lang.AssertionError,* Multiple error messages. *
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.event.rdb.JobEventRdbSearchTest.assertFindJobExecutionEventsWithTime,java.lang.AssertionError,* Multiple error messages. *
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-lifecycle,io.elasticjob.lite.lifecycle.api.JobAPIFactoryTest.assertCreateServerStatisticsAPI,io.elasticjob.lite.reg.exception.RegException, java.net.BindException: Address already in use\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-lifecycle,io.elasticjob.lite.lifecycle.api.JobAPIFactoryTest.assertCreateJobStatisticsAPI,io.elasticjob.lite.reg.exception.RegException, org.apache.zookeeper.KeeperException$OperationTimeoutException: KeeperErrorCode = OperationTimeout\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-spring,io.elasticjob.lite.spring.job.JobSpringNamespaceWithListenerAndJdkDynamicProxyTest.assertSpringJobBean,io.elasticjob.lite.reg.exception.RegException, java.net.BindException: Address already in use\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-spring,io.elasticjob.lite.spring.job.JobSpringNamespaceWithoutListenerTest.assertSpringJobBean,io.elasticjob.lite.reg.exception.RegException, java.net.BindException: Address already in use\\n
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.gateway.EventBasedGatewayTest.testCatchTimerCancelsSignal,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.event.error.ErrorEventSubProcessTest.testErrorCodeTakesPrecedence,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.async.AsyncTaskTest.testAsyncEndEvent,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.cCreateStandaloneTaskForGroupAndClaim,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeClaimReleaseTest.aCreateStandaloneTaskForGroup,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeUnAuthorizedTest.bClaimNotFoundBecauseYouAreNotACandidate,java.lang.Exception,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeClaimReleaseTest.fCreateStandaloneTaskAndClaimAndReleaseUnAuthorized,java.lang.Exception,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.bCreateCheckTaskCreatedForSalaboyFromAnotherUser,java.lang.AssertionError, \\nExpected size:<1> but was:<0> in:\\n<[]>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeDeleteTaskTest.aCreateStandaloneTaskAndDelete,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeClaimReleaseTest.bClaimAndRelease,org.activiti.api.runtime.shared.NotFoundException,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.aCreateStandaloneTaskAndComplete,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.aCreateStandaloneTaskForAnotherAssignee,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.ctryCompletingWithUnauthorizedUser,java.lang.Exception, Unexpected exception; expected<org.activiti.api.runtime.shared.NotFoundException> but was<org.activiti.engine.ActivitiIllegalArgumentException>\\n
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeStandaloneTaskTest.bCreateStandaloneTaskForGroup,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.fileSystemCache,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.fileSystemExecutor,org.apache.hadoop.lib.service.FileSystemAccessException, H03: FileSystemExecutor error; org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.servlet.TestServerWebApp.getHomeDirNotDef,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.test.TestHFSTestCase.testHadoopFileSystem,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.createFileSystem,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testDisallowSnapshot,java.lang.RuntimeException, Could not stop embedded servlet container; Server is not running\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testAllowSnapshot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testPerms,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testDisallowSnapshot,java.io.IOException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testOpenOffsetLength,java.io.FileNotFoundException, /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/dfs/name-0-1/current/seen_txid.tmp (No such file or directory)\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.lib.servlet.TestServerWebApp.getHomeDirNotDef,java.lang.InterruptedException, sleep interrupted\\n08:23:12;883  INFO Server:621 - Services destroyed\\n08:23:12;883  INFO Server:633 - Server [httpfs] shutdown!\\n08:23:12;883  INFO Server:634 - ======================================================\\n08:23:12;920  WARN Server:433 - Log4j [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-log4j.properties] configuration file not found; using default configuration from classpath\\n08:23:12;921  INFO Server:359 - ++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n08:23:12;921  INFO Server:360 - Server [httpfs] starting\\n08:23:12;921  INFO Server:361 -   Built information:\\n08:23:12;921  INFO Server:362 -     Version           : 3.3.0-SNAPSHOT\\n08:23:12;922  INFO Server:363 -     Source Repository : REPO NOT AVAIL\\n08:23:12;922  INFO Server:364 -     Source Revision   : REVISION NOT AVAIL\\n08:23:12;922  INFO Server:365 -     Built by          : colossus2\\n08:23:12;922  INFO Server:366 -     Built timestamp   : 2018-10-13T08:11:07+0000\\n08:23:12;922  INFO Server:367 -   Runtime information:\\n08:23:12;922  INFO Server:368 -     Home   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n08:23:12;922  INFO Server:369 -     Config dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n08:23:12;922  INFO Server:370 -     Log    dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n08:23:12;922  INFO Server:371 -     Temp   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/temp\\n08:23:12;923  WARN Server:465 - Site configuration file [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-site.xml] not found in config directory\\n08:23:12;923  INFO Server:492 - System property sets  httpfs.config.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n08:23:12;923  INFO Server:492 - System property sets  httpfs.log.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n08:23:12;924  INFO Server:492 - System property sets  httpfs.home.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n08:23:12;925  INFO FileSystemAccessService:149 - Using FileSystemAccess JARs version [3.3.0-SNAPSHOT]\\n08:23:12;931  INFO FileSystemAccessService:176 - Using FileSystemAccess simple/pseudo authentication; principal [colossus2]\\n08:23:12;939  INFO Server:378 - Services initialized\\n08:23:12;940  INFO Server:386 - Server [httpfs] started!; status [NORMAL]\\n08:23:12;945  INFO HttpFSServerWebApp:102 - Connects to Namenode [file:///]\\n08:23:12;945  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\nOct 13; 2018 8:23:12 AM com.sun.jersey.api.core.PackagesResourceConfig init\\nINFO: Scanning for root resource and provider classes in the packages:\\n  org.apache.hadoop.fs.http.server\\n  org.apache.hadoop.lib.wsrs\\nOct 13; 2018 8:23:12 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Root resource classes found:\\n  class org.apache.hadoop.fs.http.server.HttpFSServer\\nOct 13; 2018 8:23:12 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Provider classes found:\\n  class org.apache.hadoop.lib.wsrs.JSONMapProvider\\n  class org.apache.hadoop.fs.http.server.HttpFSParametersProvider\\n  class org.apache.hadoop.fs.http.server.HttpFSExceptionProvider\\n  class org.apache.hadoop.lib.wsrs.JSONProvider\\n08:23:12;959  INFO AbstractDelegationTokenSecretManager:675 - Starting expired delegation token remover thread; tokenRemoverScanInterval=60 min(s)\\n08:23:12;962  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\nOct 13; 2018 8:23:12 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\\nINFO: Initiating Jersey application; version 'Jersey: 1.19 02/11/2015 03:25 AM'\\n08:23:13;043  INFO ContextHandler:781 - Started o.e.j.w.WebAppContext@2b16fa74{/;file:///home/colossus2/apache/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/classes/webapps/webhdfs/;AVAILABLE}{/webhdfs}\\n08:23:13;043  INFO AbstractConnector:278 - Started ServerConnector@5d11a5d{HTTP/1.1;[http/1.1]}{localhost:46777}\\n08:23:13;046  INFO Server:414 - Started @19764ms\\n08:23:13;299  INFO httpfsaudit:259 - [/] filter [-]\\n08:23:13;301 ERROR AbstractDelegationTokenSecretManager:696 - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\\n08:23:13;301  INFO Server:621 - Services destroyed\\n08:23:13;301  INFO Server:633 - Server [httpfs] shutdown!\\n08:23:13;301  INFO Server:634 - ======================================================\\n08:23:13;364  WARN Server:433 - Log4j [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-log4j.properties] configuration file not found; using default configuration from classpath\\n08:23:13;364  INFO Server:359 - ++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n08:23:13;364  INFO Server:360 - Server [httpfs] starting\\n08:23:13;364  INFO Server:361 -   Built information:\\n08:23:13;364  INFO Server:362 -     Version           : 3.3.0-SNAPSHOT\\n08:23:13;364  INFO Server:363 -     Source Repository : REPO NOT AVAIL\\n08:23:13;364  INFO Server:364 -     Source Revision   : REVISION NOT AVAIL\\n08:23:13;364  INFO Server:365 -     Built by          : colossus2\\n08:23:13;364  INFO Server:366 -     Built timestamp   : 2018-10-13T08:11:07+0000\\n08:23:13;364  INFO Server:367 -   Runtime information:\\n08:23:13;364  INFO Server:368 -     Home   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n08:23:13;364  INFO Server:369 -     Config dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n08:23:13;364  INFO Server:370 -     Log    dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n08:23:13;364  INFO Server:371 -     Temp   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/temp\\n08:23:13;366  WARN Server:465 - Site configuration file [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-site.xml] not found in config directory\\n08:23:13;366  INFO Server:492 - System property sets  httpfs.config.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n08:23:13;366  INFO Server:492 - System property sets  httpfs.log.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n08:23:13;366  INFO Server:492 - System property sets  httpfs.home.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n08:23:13;367  INFO FileSystemAccessService:149 - Using FileSystemAccess JARs version [3.3.0-SNAPSHOT]\\n08:23:13;372  INFO FileSystemAccessService:176 - Using FileSystemAccess simple/pseudo authentication; principal [colossus2]\\n08:23:13;384  INFO Server:378 - Services initialized\\n08:23:13;384  INFO Server:386 - Server [httpfs] started!; status [NORMAL]\\n08:23:13;389  INFO HttpFSServerWebApp:102 - Connects to Namenode [file:///]\\n08:23:13;389  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\nOct 13; 2018 8:23:13 AM com.sun.jersey.api.core.PackagesResourceConfig init\\nINFO: Scanning for root resource and provider classes in the packages:\\n  org.apache.hadoop.fs.http.server\\n  org.apache.hadoop.lib.wsrs\\nOct 13; 2018 8:23:13 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Root resource classes found:\\n  class org.apache.hadoop.fs.http.server.HttpFSServer\\nOct 13; 2018 8:23:13 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Provider classes found:\\n  class org.apache.hadoop.lib.wsrs.JSONMapProvider\\n  class org.apache.hadoop.fs.http.server.HttpFSParametersProvider\\n  class org.apache.hadoop.fs.http.server.HttpFSExceptionProvider\\n  class org.apache.hadoop.lib.wsrs.JSONProvider\\nOct 13; 2018 8:23:13 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\\nINFO: Initiating Jersey application; version 'Jersey: 1.19 02/11/2015 03:25 AM'\\n08:23:13;407  INFO AbstractDelegationTokenSecretManager:675 - Starting expired delegation token remover thread; tokenRemoverScanInterval=60 min(s)\\n08:23:13;410  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\n08:23:13;490  INFO ContextHandler:781 - Started o.e.j.w.WebAppContext@5be418f2{/;file:///home/colossus2/apache/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/classes/webapps/webhdfs/;AVAILABLE}{/webhdfs}\\n08:23:13;491  INFO AbstractConnector:278 - Started ServerConnector@614a400c{HTTP/1.1;[http/1.1]}{localhost:46861}\\n08:23:13;491  INFO Server:414 - Started @20209ms\\n08:23:13;491 ERROR AbstractDelegationTokenSecretManager:696 - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\\n08:23:13;492  INFO Server:621 - Services destroyed\\n08:23:13;492  INFO Server:633 - Server [httpfs] shutdown!\\n08:23:13;492  INFO Server:634 - ======================================================\\n08:23:13;568  WARN Server:433 - Log4j [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-log4j.properties] configuration file not found; using default configuration from classpath\\n08:23:13;568  INFO Server:359 - ++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n08:23:13;568  INFO Server:360 - Server [httpfs] starting\\n08:23:13;569  INFO Server:361 -   Built information:\\n08:23:13;569  INFO Server:362 -     Version           : 3.3.0-SNAPSHOT\\n08:23:13;569  INFO Server:363 -     Source Repository : REPO NOT AVAIL\\n08:23:13;569  INFO Server:364 -     Source Revision   : REVISION NOT AVAIL\\n08:23:13;569  INFO Server:365 -     Built by          : colossus2\\n08:23:13;569  INFO Server:366 -     Built timestamp   : 2018-10-13T08:11:07+0000\\n08:23:13;569  INFO Server:367 -   Runtime information:\\n08:23:13;569  INFO Server:368 -     Home   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n08:23:13;569  INFO Server:369 -     Config dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n08:23:13;569  INFO Server:370 -     Log    dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n08:23:13;569  INFO Server:371 -     Temp   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/temp\\n08:23:13;570  WARN Server:465 - Site configuration file [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-site.xml] not found in config directory\\n08:23:13;571  INFO Server:492 - System property sets  httpfs.config.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n08:23:13;571  INFO Server:492 - System property sets  httpfs.log.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n08:23:13;571  INFO Server:492 - System property sets  httpfs.home.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n08:23:13;572  INFO FileSystemAccessService:149 - Using FileSystemAccess JARs version [3.3.0-SNAPSHOT]\\n08:23:13;584  INFO FileSystemAccessService:176 - Using FileSystemAccess simple/pseudo authentication; principal [colossus2]\\n08:23:13;596  INFO Server:378 - Services initialized\\n08:23:13;596  INFO Server:386 - Server [httpfs] started!; status [NORMAL]\\n08:23:13;601  INFO HttpFSServerWebApp:102 - Connects to Namenode [file:///]\\n08:23:13;601  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\nOct 13; 2018 8:23:13 AM com.sun.jersey.api.core.PackagesResourceConfig init\\nINFO: Scanning for root resource and provider classes in the packages:\\n  org.apache.hadoop.fs.http.server\\n  org.apache.hadoop.lib.wsrs\\nOct 13; 2018 8:23:13 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Root resource classes found:\\n  class org.apache.hadoop.fs.http.server.HttpFSServer\\nOct 13; 2018 8:23:13 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Provider classes found:\\n  class org.apache.hadoop.lib.wsrs.JSONMapProvider\\n  class org.apache.hadoop.fs.http.server.HttpFSParametersProvider\\n  class org.apache.hadoop.fs.http.server.HttpFSExceptionProvider\\n  class org.apache.hadoop.lib.wsrs.JSONProvider\\nOct 13; 2018 8:23:13 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\\nINFO: Initiating Jersey application; version 'Jersey: 1.19 02/11/2015 03:25 AM'\\n08:23:13;617  INFO AbstractDelegationTokenSecretManager:675 - Starting expired delegation token remover thread; tokenRemoverScanInterval=60 min(s)\\n08:23:13;621  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\n08:23:13;730  INFO ContextHandler:781 - Started o.e.j.w.WebAppContext@2501651b{/;file:///home/colossus2/apache/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/classes/webapps/webhdfs/;AVAILABLE}{/webhdfs}\\n08:23:13;735  INFO AbstractConnector:278 - Started ServerConnector@3a9569fa{HTTP/1.1;[http/1.1]}{localhost:46739}\\n08:23:13;736  INFO Server:414 - Started @20454ms\\n08:23:13;737 ERROR AbstractDelegationTokenSecretManager:696 - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\\n08:23:13;738  INFO Server:621 - Services destroyed\\n08:23:13;738  INFO Server:633 - Server [httpfs] shutdown!\\n08:23:13;738  INFO Server:634 - ======================================================\\njava.lang.AssertionError: Expected exception: java.lang.IllegalArgumentException\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testAllowSnapshot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterShutDownJob,java.lang.AssertionError, Expected shutDownJob to exit with status code of 0. expected:<0> but was:<1>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher.testSlowNM,org.apache.hadoop.yarn.exceptions.YarnRuntimeException, could not cleanup test dir\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOverlappingWrites,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testWriteStableHow,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRename,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsinfo,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testSetattr,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testPathconf,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCreate,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRead,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRmdir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReadlink,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddirplus,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCommit,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testMkdir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRemove,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testAccess,java.lang.AssertionError, Incorrect return code expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testSymlink,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsRenameSingleNN,java.lang.AssertionError, expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testLookup,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testGetattr,java.lang.AssertionError, Incorrect return code expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsstat,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testWrongNfsAccess,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testWrite,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenEnabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.ExceptionInInitializerError,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOverlappingWrites,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testWriteStableHow,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRename,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsinfo,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testSetattr,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testPathconf,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCreate,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCommit,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRemove,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testAccess,java.lang.AssertionError, Incorrect return code expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsRenameSingleNN,java.lang.AssertionError, expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testLookup,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsstat,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testWrongNfsAccess,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.mapred.TestJobEndNotifier.testNotificationTimeout,java.lang.AssertionError,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOverlappingWrites,java.io.IOException, renameTo(src=/home/colossus2/apache/hadoop/target/test/data/dfs/name-0-1/current/seen_txid.tmp; dst=/home/colossus2/apache/hadoop/target/test/data/dfs/name-0-1/current/seen_txid) failed.\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testWriteStableHow,org.apache.hadoop.hdfs.server.common.InconsistentFSStateException, Directory /home/colossus2/apache/hadoop/target/test/data/dfs/name-0-2 is in an inconsistent state: namespaceID is incompatible with others.\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRename,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOOOWrites,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsinfo,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testSetattr,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testPathconf,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN1,java.lang.AssertionError, Incorrect response: expected:<null> but was:<org.apache.hadoop.nfs.nfs3.response.WRITE3Response@22c7884b>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCreate,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN2,java.lang.AssertionError, Incorrect response: expected:<null> but was:<org.apache.hadoop.nfs.nfs3.response.WRITE3Response@561357bc>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRead,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReadlink,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCommit,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRemove,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testAccess,java.lang.AssertionError, Incorrect return code expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsRenameSingleNN,java.lang.AssertionError, expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testLookup,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testGetattr,java.lang.AssertionError, Incorrect return code expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsstat,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testWrongNfsAccess,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-hs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testWrite,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenEnabled,java.lang.ExceptionInInitializerError,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testWriteStableHow,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-jobclient,org.apache.hadoop.hdfs.nfs.nfs3.TestExportsTable.testViewFsMultipleExportPoint,java.io.IOException, Timed out waiting for Mini HDFS Cluster to start\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-registry,org.apache.hadoop.registry.secure.TestSecureLogins.testUGILogin,org.apache.hadoop.security.KerberosAuthException, failure to login: for principal: zookeeper from keytab /home/colossus2/apache/hadoop/target/kdc/zookeeper.keytab javax.security.auth.login.LoginException: Integrity check on decrypted field failed (31) - PREAUTH_FAILED\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-registry,org.apache.hadoop.lib.servlet.TestServerWebApp.getHomeDirNotDef,java.lang.InterruptedException, sleep interrupted\\n09:30:14;846  INFO Server:621 - Services destroyed\\n09:30:14;846  INFO Server:633 - Server [httpfs] shutdown!\\n09:30:14;846  INFO Server:634 - ======================================================\\n09:30:14;906  WARN Server:433 - Log4j [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-log4j.properties] configuration file not found; using default configuration from classpath\\n09:30:14;906  INFO Server:359 - ++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n09:30:14;906  INFO Server:360 - Server [httpfs] starting\\n09:30:14;906  INFO Server:361 -   Built information:\\n09:30:14;906  INFO Server:362 -     Version           : 3.3.0-SNAPSHOT\\n09:30:14;906  INFO Server:363 -     Source Repository : REPO NOT AVAIL\\n09:30:14;906  INFO Server:364 -     Source Revision   : REVISION NOT AVAIL\\n09:30:14;906  INFO Server:365 -     Built by          : colossus2\\n09:30:14;906  INFO Server:366 -     Built timestamp   : 2018-10-13T09:17:38+0000\\n09:30:14;906  INFO Server:367 -   Runtime information:\\n09:30:14;906  INFO Server:368 -     Home   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n09:30:14;906  INFO Server:369 -     Config dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n09:30:14;906  INFO Server:370 -     Log    dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n09:30:14;907  INFO Server:371 -     Temp   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/temp\\n09:30:14;911  WARN Server:465 - Site configuration file [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-site.xml] not found in config directory\\n09:30:14;912  INFO Server:492 - System property sets  httpfs.config.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n09:30:14;912  INFO Server:492 - System property sets  httpfs.log.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n09:30:14;912  INFO Server:492 - System property sets  httpfs.home.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n09:30:14;914  INFO FileSystemAccessService:149 - Using FileSystemAccess JARs version [3.3.0-SNAPSHOT]\\n09:30:14;919  INFO FileSystemAccessService:176 - Using FileSystemAccess simple/pseudo authentication; principal [colossus2]\\n09:30:14;934  INFO Server:378 - Services initialized\\n09:30:14;934  INFO Server:386 - Server [httpfs] started!; status [NORMAL]\\n09:30:14;939  INFO HttpFSServerWebApp:102 - Connects to Namenode [file:///]\\n09:30:14;940  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\nOct 13; 2018 9:30:14 AM com.sun.jersey.api.core.PackagesResourceConfig init\\nINFO: Scanning for root resource and provider classes in the packages:\\n  org.apache.hadoop.fs.http.server\\n  org.apache.hadoop.lib.wsrs\\nOct 13; 2018 9:30:14 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Root resource classes found:\\n  class org.apache.hadoop.fs.http.server.HttpFSServer\\nOct 13; 2018 9:30:14 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Provider classes found:\\n  class org.apache.hadoop.fs.http.server.HttpFSExceptionProvider\\n  class org.apache.hadoop.lib.wsrs.JSONMapProvider\\n  class org.apache.hadoop.fs.http.server.HttpFSParametersProvider\\n  class org.apache.hadoop.lib.wsrs.JSONProvider\\n09:30:14;958  INFO AbstractDelegationTokenSecretManager:675 - Starting expired delegation token remover thread; tokenRemoverScanInterval=60 min(s)\\n09:30:14;971  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\nOct 13; 2018 9:30:14 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\\nINFO: Initiating Jersey application; version 'Jersey: 1.19 02/11/2015 03:25 AM'\\n09:30:15;111  INFO ContextHandler:781 - Started o.e.j.w.WebAppContext@45a63b9c{/;file:///home/colossus2/apache/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/classes/webapps/webhdfs/;AVAILABLE}{/webhdfs}\\n09:30:15;111  INFO AbstractConnector:278 - Started ServerConnector@11ab4b85{HTTP/1.1;[http/1.1]}{localhost:35781}\\n09:30:15;111  INFO Server:414 - Started @19663ms\\n09:30:15;793  INFO httpfsaudit:259 - [/] filter [-]\\n09:30:15;796 ERROR AbstractDelegationTokenSecretManager:696 - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\\n09:30:15;796  INFO Server:621 - Services destroyed\\n09:30:15;796  INFO Server:633 - Server [httpfs] shutdown!\\n09:30:15;796  INFO Server:634 - ======================================================\\n09:30:15;951  WARN Server:433 - Log4j [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-log4j.properties] configuration file not found; using default configuration from classpath\\n09:30:15;952  INFO Server:359 - ++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n09:30:15;952  INFO Server:360 - Server [httpfs] starting\\n09:30:15;952  INFO Server:361 -   Built information:\\n09:30:15;952  INFO Server:362 -     Version           : 3.3.0-SNAPSHOT\\n09:30:15;952  INFO Server:363 -     Source Repository : REPO NOT AVAIL\\n09:30:15;952  INFO Server:364 -     Source Revision   : REVISION NOT AVAIL\\n09:30:15;952  INFO Server:365 -     Built by          : colossus2\\n09:30:15;952  INFO Server:366 -     Built timestamp   : 2018-10-13T09:17:38+0000\\n09:30:15;952  INFO Server:367 -   Runtime information:\\n09:30:15;952  INFO Server:368 -     Home   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n09:30:15;952  INFO Server:369 -     Config dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n09:30:15;952  INFO Server:370 -     Log    dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n09:30:15;952  INFO Server:371 -     Temp   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/temp\\n09:30:15;953  WARN Server:465 - Site configuration file [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-site.xml] not found in config directory\\n09:30:15;953  INFO Server:492 - System property sets  httpfs.config.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n09:30:15;954  INFO Server:492 - System property sets  httpfs.log.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n09:30:15;954  INFO Server:492 - System property sets  httpfs.home.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n09:30:15;954  INFO FileSystemAccessService:149 - Using FileSystemAccess JARs version [3.3.0-SNAPSHOT]\\n09:30:15;965  INFO FileSystemAccessService:176 - Using FileSystemAccess simple/pseudo authentication; principal [colossus2]\\n09:30:15;979  INFO Server:378 - Services initialized\\n09:30:15;979  INFO Server:386 - Server [httpfs] started!; status [NORMAL]\\n09:30:15;984  INFO HttpFSServerWebApp:102 - Connects to Namenode [file:///]\\n09:30:15;984  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\nOct 13; 2018 9:30:15 AM com.sun.jersey.api.core.PackagesResourceConfig init\\nINFO: Scanning for root resource and provider classes in the packages:\\n  org.apache.hadoop.fs.http.server\\n  org.apache.hadoop.lib.wsrs\\nOct 13; 2018 9:30:16 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Root resource classes found:\\n  class org.apache.hadoop.fs.http.server.HttpFSServer\\nOct 13; 2018 9:30:16 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Provider classes found:\\n  class org.apache.hadoop.fs.http.server.HttpFSExceptionProvider\\n  class org.apache.hadoop.lib.wsrs.JSONMapProvider\\n  class org.apache.hadoop.fs.http.server.HttpFSParametersProvider\\n  class org.apache.hadoop.lib.wsrs.JSONProvider\\nOct 13; 2018 9:30:16 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\\nINFO: Initiating Jersey application; version 'Jersey: 1.19 02/11/2015 03:25 AM'\\n09:30:16;006  INFO AbstractDelegationTokenSecretManager:675 - Starting expired delegation token remover thread; tokenRemoverScanInterval=60 min(s)\\n09:30:16;019  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\n09:30:16;152  INFO ContextHandler:781 - Started o.e.j.w.WebAppContext@26f5e86b{/;file:///home/colossus2/apache/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/classes/webapps/webhdfs/;AVAILABLE}{/webhdfs}\\n09:30:16;153  INFO AbstractConnector:278 - Started ServerConnector@67902a48{HTTP/1.1;[http/1.1]}{localhost:46133}\\n09:30:16;153  INFO Server:414 - Started @20705ms\\n09:30:16;153 ERROR AbstractDelegationTokenSecretManager:696 - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\\n09:30:16;154  INFO Server:621 - Services destroyed\\n09:30:16;154  INFO Server:633 - Server [httpfs] shutdown!\\n09:30:16;154  INFO Server:634 - ======================================================\\n09:30:16;189  WARN Server:433 - Log4j [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-log4j.properties] configuration file not found; using default configuration from classpath\\n09:30:16;189  INFO Server:359 - ++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n09:30:16;189  INFO Server:360 - Server [httpfs] starting\\n09:30:16;189  INFO Server:361 -   Built information:\\n09:30:16;189  INFO Server:362 -     Version           : 3.3.0-SNAPSHOT\\n09:30:16;189  INFO Server:363 -     Source Repository : REPO NOT AVAIL\\n09:30:16;189  INFO Server:364 -     Source Revision   : REVISION NOT AVAIL\\n09:30:16;189  INFO Server:365 -     Built by          : colossus2\\n09:30:16;189  INFO Server:366 -     Built timestamp   : 2018-10-13T09:17:38+0000\\n09:30:16;189  INFO Server:367 -   Runtime information:\\n09:30:16;189  INFO Server:368 -     Home   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n09:30:16;189  INFO Server:369 -     Config dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n09:30:16;189  INFO Server:370 -     Log    dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n09:30:16;190  INFO Server:371 -     Temp   dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/temp\\n09:30:16;190  WARN Server:465 - Site configuration file [/home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop/httpfs-site.xml] not found in config directory\\n09:30:16;191  INFO Server:492 - System property sets  httpfs.config.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/etc/hadoop\\n09:30:16;191  INFO Server:492 - System property sets  httpfs.log.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data/logs\\n09:30:16;191  INFO Server:492 - System property sets  httpfs.home.dir: /home/colossus2/apache/hadoop/target/test-dir/hadoop-data\\n09:30:16;192  INFO FileSystemAccessService:149 - Using FileSystemAccess JARs version [3.3.0-SNAPSHOT]\\n09:30:16;197  INFO FileSystemAccessService:176 - Using FileSystemAccess simple/pseudo authentication; principal [colossus2]\\n09:30:16;215  INFO Server:378 - Services initialized\\n09:30:16;239  INFO Server:386 - Server [httpfs] started!; status [NORMAL]\\n09:30:16;245  INFO HttpFSServerWebApp:102 - Connects to Namenode [file:///]\\n09:30:16;245  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\n09:30:16;255  INFO AbstractDelegationTokenSecretManager:675 - Starting expired delegation token remover thread; tokenRemoverScanInterval=60 min(s)\\n09:30:16;258  INFO AbstractDelegationTokenSecretManager:343 - Updating the current master key for generating delegation tokens\\nOct 13; 2018 9:30:16 AM com.sun.jersey.api.core.PackagesResourceConfig init\\nINFO: Scanning for root resource and provider classes in the packages:\\n  org.apache.hadoop.fs.http.server\\n  org.apache.hadoop.lib.wsrs\\nOct 13; 2018 9:30:16 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Root resource classes found:\\n  class org.apache.hadoop.fs.http.server.HttpFSServer\\nOct 13; 2018 9:30:16 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses\\nINFO: Provider classes found:\\n  class org.apache.hadoop.fs.http.server.HttpFSExceptionProvider\\n  class org.apache.hadoop.lib.wsrs.JSONMapProvider\\n  class org.apache.hadoop.fs.http.server.HttpFSParametersProvider\\n  class org.apache.hadoop.lib.wsrs.JSONProvider\\nOct 13; 2018 9:30:16 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\\nINFO: Initiating Jersey application; version 'Jersey: 1.19 02/11/2015 03:25 AM'\\n09:30:16;481  INFO ContextHandler:781 - Started o.e.j.w.WebAppContext@171b0c9e{/;file:///home/colossus2/apache/hadoop/hadoop-hdfs-project/hadoop-hdfs-httpfs/target/classes/webapps/webhdfs/;AVAILABLE}{/webhdfs}\\n09:30:16;487  INFO AbstractConnector:278 - Started ServerConnector@2be5f017{HTTP/1.1;[http/1.1]}{localhost:44897}\\n09:30:16;488  INFO Server:414 - Started @21040ms\\n09:30:16;488 ERROR AbstractDelegationTokenSecretManager:696 - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\\n09:30:16;489  INFO Server:621 - Services destroyed\\n09:30:16;489  INFO Server:633 - Server [httpfs] shutdown!\\n09:30:16;489  INFO Server:634 - ======================================================\\njava.lang.AssertionError: Expected exception: java.lang.IllegalArgumentException\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-router,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-router,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError, expected:<500> but was:<400>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-router,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenEnabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-router,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-router,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.ExceptionInInitializerError,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-router,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-router,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-router,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.ExceptionInInitializerError,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenEnabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOverlappingWrites,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testWriteStableHow,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-sharedcachemanager,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOOOWrites,c8d5f28a987d_15394java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.fs.http.server.TestHttpFSServer.testFileAcls,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.fs.http.server.TestHttpFSServer.testAllowSnapshot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.fs.http.server.TestHttpFSServer.testGetTrashRoot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.fs.http.server.TestHttpFSServer.instrumentation,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.fs.http.server.TestHttpFSServer.testPerms,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.registry.secure.TestSecureLogins.testKerberosRulesValid,java.lang.IllegalArgumentException, Can't get Kerberos realm\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.registry.client.impl.TestCuratorService.testRM,org.apache.hadoop.fs.PathIsNotEmptyDirectoryException, `/registry/rm': Directory is not empty: KeeperErrorCode = Directory not empty for /registry/rm\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.registry.secure.TestSecureLogins.testDefaultRealmValid,java.lang.reflect.InvocationTargetException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestLogInfo.testParseDomain,java.io.IOException, Timed out waiting for Mini HDFS Cluster to start\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestLogInfo.testParseBrokenEntity,java.io.IOException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestLogInfo.testParseEntity,java.io.IOException, Cannot lock storage /home/colossus2/apache/hadoop/target/test/data/dfs/name-0-1. The directory is already locked\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestLogInfo.testMatchesGroupId,java.io.IOException, Timed out waiting for Mini HDFS Cluster to start\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testGetEntityPluginRead,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testMoveToDone,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timeline-pluginstorage,org.apache.hadoop.yarn.server.timeline.TestEntityGroupFSTimelineStore.testParseSummaryLogs,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.fs.http.server.TestHttpFSServer.testAllowSnapshot,java.lang.InterruptedException, sleep interrupted\\n09:32:02;548  INFO Server:621 - Services destroyed\\n09:32:02;548  INFO Server:633 - Server [httpfs] shutdown!\\n09:32:02;548  INFO Server:634 - ======================================================\\njava.io.FileNotFoundException: File does not exist: /tmp/tmp-snap-allow-test\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.fs.http.server.TestHttpFSServer.testGetTrashRoot,java.lang.InterruptedException, sleep interrupted\\n09:31:59;925  INFO Server:621 - Services destroyed\\n09:31:59;925  INFO Server:633 - Server [httpfs] shutdown!\\n09:31:59;925  INFO Server:634 - ======================================================\\norg.junit.ComparisonFailure: expected:</[user/user1]/.Trash> but was:</[home/colossus2]/.Trash>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.fs.http.server.TestHttpFSServer.testPerms,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.registry.secure.TestSecureLogins.testKerberosRulesValid,java.lang.IllegalArgumentException, Can't get Kerberos realm\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.registry.secure.TestSecureLogins.testDefaultRealmValid,java.lang.reflect.InvocationTargetException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOverlappingWrites,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testWriteStableHow,java.io.IOException, Timed out waiting for Mini HDFS Cluster to start\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRename,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOOOWrites,java.io.IOException, Timed out waiting for Mini HDFS Cluster to start\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsRenameSingleNN,java.lang.AssertionError, expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testPathconf,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN1,java.lang.AssertionError, Incorrect response: expected:<null> but was:<org.apache.hadoop.nfs.nfs3.response.WRITE3Response@41151d21>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN2,java.lang.AssertionError, Incorrect response: expected:<null> but was:<org.apache.hadoop.nfs.nfs3.response.WRITE3Response@11e5615c>\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-hadoop-yarn-server-timelineservice-hbase-client,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testWrongNfsAccess,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.fs.http.server.TestHttpFSServer.testAllowSnapshot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.fs.http.server.TestHttpFSServer.testGetTrashRoot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.fileSystemCache,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.fileSystemExecutor,org.apache.hadoop.lib.service.FileSystemAccessException, H03: FileSystemExecutor error; org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.lib.servlet.TestServerWebApp.getHomeDirNotDef,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.test.TestHFSTestCase.testHadoopFileSystem,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.createFileSystem,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction.testWriteScanBatchLimit,java.lang.AssertionError, expected:<4> but was:<5>\\n
apache.hbase,hbase-hbase-zookeeper,org.apache.hadoop.hbase.zookeeper.TestInstancePending.test,java.lang.InterruptedException, sleep interrupted\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-cluster,org.apache.dubbo.rpc.cluster.support.ForkingClusterInvokerTest.testClearRpcContext,java.lang.AssertionError, set attachment failed!\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-cluster,org.apache.dubbo.rpc.cluster.StickyTest.testStickyNoCheck,java.lang.AssertionError,
apache.incubator-dubbo,incubator-dubbo-dubbo-cluster,org.apache.dubbo.rpc.cluster.support.AbstractClusterInvokerTest.testBindingAttachment,java.lang.AssertionError, set attachment failed!\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-cluster,org.apache.dubbo.rpc.cluster.StickyTest.testMethodStickyNoCheck,java.lang.AssertionError,
apache.incubator-dubbo,incubator-dubbo-dubbo-common,org.apache.dubbo.common.threadlocal.InternalThreadLocalTest.testSize,java.lang.AssertionError, size method is wrong!\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.AbstractInterfaceConfigTest.testLoadRegistries,java.lang.IllegalStateException, the temporary folder has not yet been created\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.AbstractInterfaceConfigTest.testListener,java.lang.IllegalStateException, the temporary folder has not yet been created\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.ReferenceConfigTest.testInjvm,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.validation.ValidationTest.testGenericValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.validation.ValidationTest.testProviderValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.cache.CacheTest.testCache,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.validation.ValidationTest.testValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.ReferenceConfigTest.testInjvm,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.AbstractInterfaceConfigTest.testListener,java.lang.IllegalStateException, the temporary folder has not yet been created\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.validation.ValidationTest.testGenericValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.validation.ValidationTest.testProviderValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.cache.CacheTest.testCache,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.validation.ValidationTest.testValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.spring.beans.factory.annotation.ServiceAnnotationBeanPostProcessorTest.test,java.lang.IllegalStateException, Failed to load ApplicationContext\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-filter-dubbo-filter-cache,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-monitor-dubbo-monitor-default,org.apache.dubbo.rpc.protocol.dubbo.DubboLazyConnectTest.testSticky1,org.apacjava.lang.AssertionError, Expected exception: org.apache.dubbo.rpc.RpcException\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-monitor-dubbo-monitor-default,org.apache.dubbo.rpc.protocol.dubbo.MultiThreadTest.testDubboMultiThreadInvoke,org.apache.dubbo.rpc.RpcException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-monitor-dubbo-monitor-default,org.apache.dubbo.rpc.protocol.dubbo.DubboProtocolTest.testReturnNonSerialized,org.apache.dubbo.rpc.RpcException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-monitor-dubbo-monitor-default,org.apache.dubbo.rpc.protocol.dubbo.DubboProtocolTest.testNonSerializedParameter,org.apache.dubbo.rpc.RpcException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-monitor-dubbo-monitor-default,org.apache.dubbo.rpc.protocol.dubbo.DubboProtocolTest.testDemoProtocol,org.apache.dubbo.rpc.RpcException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-monitor-dubbo-monitor-default,org.apache.dubbo.rpc.protocol.dubbo.DubboProtocolTest.testPerm,org.apache.dubbo.rpc.RpcException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-default,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride_notmatch,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-default,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testDestoryRegistry,java.lang.AssertionError, expected:<false> but was:<true>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-registry-dubbo-registry-default,org.apache.dubbo.registry.dubbo.RegistryProtocolTest.testNotifyOverride,java.util.NoSuchElementException,
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-api,org.apache.dubbo.rpc.proxy.jdk.JdkProxyFactoryTest.testGetInvoker,java.lang.AssertionError,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-api,org.apache.dubbo.rpc.proxy.javassist.JavassistProxyFactoryTest.testGetInvoker,java.lang.AssertionError, expected:<java.lang.Object@453da22c> but was:<aa>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-dubbo,org.apache.dubbo.rpc.protocol.dubbo.DubboProtocolTest.testDubboProtocolWithMina,org.apache.dubbo.rpc.RpcException, Unsupported server type: mina; url: dubbo://127.0.0.1:9010/org.apache.dubbo.rpc.protocol.dubbo.support.DemoService?channel.readonly.sent=true&heartbeat=60000&server=mina\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-dubbo,org.apache.dubbo.rpc.protocol.dubbo.telnet.ListTelnetHandlerTest.testListService,org.apache.dubbo.rpc.RpcException, Fail to start server(url: dubbo://127.0.0.1:20885/demo?channel.readonly.sent=true&codec=dubbo&heartbeat=60000) Failed to bind NettyServer on /127.0.0.1:20885; cause: Address already in use\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-fst,org.apache.dubbo.common.serialize.fst.FstObjectInputTest.testEmptyByteArrayForEmptyInput,java.lang.AssertionError,* Multiple error messages. *
apache.jackrabbit-oak,jackrabbit-oak-oak-core,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.singleQueryRun,java.lang.AssertionError, expected:<1> but was:<0>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-core,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.multipleQueryRuns,java.lang.AssertionError, \\nExpected: is <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n     but: was <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-jcr,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.singleQueryRun,java.lang.AssertionError, expected:<1> but was:<0>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-jcr,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.multipleQueryRuns,java.lang.AssertionError, \\nExpected: is <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n     but: was <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-store-document,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.multipleQueryRuns,java.lang.AssertionError, \\nExpected: is <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n     but: was <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr168DispatcherTest.testRender_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr286DispatcherTest.testRender_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr286DispatcherTest.testProcessAction_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr168DispatcherTest.testProcessAction_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
crawlscript.webcollector,WebCollector-,cn.edu.hfut.dmic.webcollector.util.OkHttpRequesterTest.testHttpCode,java.lang.AssertionError, java.net.SocketTimeoutException: connect timed out\\n
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_full_collection_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_collection_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_map_key_value,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_map_key_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.bugs.TestEntityWithCaseSensitivePKIT.should_dsl_select_with_token_value,java.lang.AssertionError, \\nExpecting actual not to be null\\n
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_index_and_multi_clustering_columns_slice,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_map_key_entry,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_index_and_clustering_column,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_index_and_clustering_column_slice,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_simple_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_map_key_value_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_collection_index_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_map_key_index_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_full_collection_index_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_map_key_entry_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_10,info.archinnov.achilles.it.TestEntityForGroupByIT.should_select_sum_group_by_partition_keys_and_one_clustering,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_10,info.archinnov.achilles.it.TestEntityForGroupByIT.should_select_sum_group_by_partition_keys,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_eq_non_tokenizer,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_like_non_tokenizer,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_contains,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_prefix_non_tokenizer,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_like,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_end_with,java.lang.AssertionError, \\nExpected size:<1> but was:<6> in:\\n<[info.archinnov.achilles.internals.entities.EntityWithSASIIndices@3bd418e4; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@544820b7; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@6b98a075; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@2e61d218; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@3569fc08; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@20b12f8a]>\\n
dropwizard.dropwizard,dropwizard-dropwizard-e2e,com.example.app1.App1Test.customJsonProviderRoundtrip,java.lang.NullPointerException,
dropwizard.dropwizard,dropwizard-dropwizard-e2e,com.example.app1.App1Test.customJsonProvider,java.lang.NullPointerException,
dropwizard.dropwizard,dropwizard-dropwizard-e2e,com.example.app1.App1Test.customJsonProviderClient,java.lang.NullPointerException,
dropwizard.dropwizard,dropwizard-dropwizard-logging,io.dropwizard.logging.DefaultLoggingFactoryTest.testConfigure,java.lang.AssertionError," \\nExpecting:\\n  <[]>\\nto contain only:\\n  <[""DEBUG com.example.newApp: New application debug log"";\\n    ""INFO  com.example.newApp: New application info log""]>\\nbut could not find the following elements:\\n  <[""DEBUG com.example.newApp: New application debug log"";\\n    ""INFO  com.example.newApp: New application info log""]>\\n\\n"
dropwizard.dropwizard,dropwizard-dropwizard-logging,io.dropwizard.logging.DefaultLoggingFactoryPrintErrorMessagesTest.testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut,java.lang.AssertionError,* Multiple error messages. *
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.event.rdb.JobEventRdbSearchTest.assertFindJobExecutionEventsWithTime,java.lang.AssertionError,* Multiple error messages. *
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.event.rdb.JobEventRdbSearchTest.assertFindJobStatusTraceEventsWithTime,java.lang.AssertionError,* Multiple error messages. *
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-lifecycle,io.elasticjob.lite.lifecycle.api.JobAPIFactoryTest.assertCreateServerStatisticsAPI,io.elasticjob.lite.reg.exception.RegException, java.net.BindException: Address already in use\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-lifecycle,io.elasticjob.lite.lifecycle.api.JobAPIFactoryTest.assertCreateJobStatisticsAPI,io.elasticjob.lite.reg.exception.RegException, org.apache.zookeeper.KeeperException$OperationTimeoutException: KeeperErrorCode = OperationTimeout\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-spring,io.elasticjob.lite.spring.job.JobSpringNamespaceWithoutListenerTest.assertSpringJobBean,io.elasticjob.lite.reg.exception.RegException, java.net.BindException: Address already in use\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-spring,io.elasticjob.lite.spring.job.JobSpringNamespaceWithListenerAndJdkDynamicProxyTest.assertSpringJobBean,io.elasticjob.lite.reg.exception.RegException, java.net.BindException: Address already in use\\n
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.gateway.EventBasedGatewayTest.testCatchTimerCancelsSignal,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.event.error.ErrorEventSubProcessTest.testErrorCodeTakesPrecedence,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-engine,org.activiti.engine.test.bpmn.async.AsyncTaskTest.testAsyncEndEvent,java.lang.NullPointerException,
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.cCreateStandaloneTaskForGroupAndClaim,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.aCreateStandaloneTaskAndComplete,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeUnAuthorizedTest.bClaimNotFoundBecauseYouAreNotACandidate,java.lang.Exception,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeClaimReleaseTest.fCreateStandaloneTaskAndClaimAndReleaseUnAuthorized,java.lang.Exception,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.ctryCompletingWithUnauthorizedUser,java.lang.Exception,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.bCreateCheckTaskCreatedForSalaboyFromAnotherUser,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeDeleteTaskTest.aCreateStandaloneTaskAndDelete,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeClaimReleaseTest.aCreateStandaloneTaskForGroup,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskAssigneeTest.aCreateStandaloneTaskForAnotherAssignee,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeDeleteTaskTest.cCreateStandaloneGroupTaskClaimAndDeleteFail,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeStandaloneTaskTest.bCreateStandaloneTaskForGroup,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskForOtherTest.aCreateStandaloneTaskWithNoCandidates,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeCompleteTaskTest.bCreateStandaloneTask,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeTaskForOtherTest.bCheckThatTaskIsNotVisibleForNonCandidateUsers,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeUnAuthorizedTest.aCreateStandaloneTaskForGroup,java.lang.AssertionError,* Multiple error messages. *
activiti.activiti,Activiti-activiti-spring-boot-starter,org.activiti.spring.boot.tasks.TaskRuntimeStandaloneTaskTest.aCreateStandaloneTaskForSalaboy,java.lang.AssertionError,* Multiple error messages. *
alibaba.fastjson,fastjson-,com.alibaba.json.bvt.serializer.date.DateTest4_indian.test_date,junit.framework.AssertionFailedError, expected:<17100000> but was:<45900000>\\n
alibaba.fastjson,fastjson-,com.alibaba.json.bvt.serializer.MaxBufSizeTest.test_max_buf,junit.framework.AssertionFailedError,
apache.hadoop,hadoop-hadoop-common-project-hadoop-auth,org.apache.hadoop.security.authentication.util.TestKerberosName.testRules,KeeperException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testAllowSnapshot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.fs.http.server.TestHttpFSServer.testGetTrashRoot,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.fileSystemCache,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.fileSystemExecutor,org.apache.hadoop.lib.service.FileSystemAccessException, H03: FileSystemExecutor error; org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.servlet.TestServerWebApp.getHomeDirNotDef,java.lang.InterruptedException,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.createFileSystem,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-httpfs,org.apache.hadoop.test.TestHFSTestCase.testHadoopFileSystem,org.apache.hadoop.ipc.RemoteException,org.apache.hadoop.security.authorize.AuthorizationException): User: colossus2 is not allowed to impersonate u\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testOverlappingWrites,java.lang.NullPointerException,
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRename,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsinfo,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testSetattr,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsAccessNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testPathconf,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCreate,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN1,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsWriteNN2,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRead,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRmdir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReaddirplus,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testReadlink,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testCommit,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testMkdir,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testRemove,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testAccess,java.lang.AssertionError, Incorrect return code expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testSymlink,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testNfsRenameSingleNN,java.lang.AssertionError, expected:<0> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testLookup,java.lang.AssertionError, Incorrect return code expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testGetattr,java.lang.AssertionError, Incorrect return code expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testFsstat,java.lang.AssertionError, Incorrect return code: expected:<0> but was:<13>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestRpcProgramNfs3.testWrite,java.lang.AssertionError, Incorrect return code: expected:<13> but was:<5>\\n
apache.hadoop,hadoop-hadoop-hdfs-project-hadoop-hdfs-nfs,org.apache.hadoop.hdfs.nfs.nfs3.TestViewfsWithNfs3.testWrongNfsAccess,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-app,org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterShutDownJob,java.lang.AssertionError, Expected shutDownJob to exit with status code of 0. expected:<0> but was:<1>\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-mapreduce-project-hadoop-mapreduce-client-hadoop-mapreduce-client-core,org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue,java.lang.ClassCastException, org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$RLFS cannot be cast to org.apache.hadoop.fs.LocalFileSystem\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-registry,org.apache.hadoop.registry.secure.TestSecureLogins.testUGILogin,org.apache.hadoop.security.KerberosAuthException, failure to login: for principal: zookeeper from keytab /home/colossus2/apache/hadoop/target/kdc/zookeeper.keytab javax.security.auth.login.LoginException: Integrity check on decrypted field failed (31) - PREAUTH_FAILED\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByMetricFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByInfoFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesWithLimit,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testAbout,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityAllFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainers,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityDefaultView,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityWithUserAndFlowInfo,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesBasedOnCreatedTime,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testInvalidValuesHandling,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByConfigFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntities,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenEnabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityNotPresent,java.lang.AssertionError,* Multiple error messages. *
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntityCustomFields,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testQueryWithoutCluster,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetContainer,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesNoMatch,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServicesBasicAcl.testTimelineReaderManagerAclsWhenDisabled,java.lang.NoClassDefFoundError, Could not initialize class org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempts,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByRelations,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetAppAttempt,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice,org.apache.hadoop.yarn.server.timelineservice.reader.TestTimelineReaderWebServices.testGetEntitiesByEventFilters,java.io.IOException, Incorrect response from timeline reader. Status=500\\n
apache.hadoop,hadoop-hadoop-yarn-project-hadoop-yarn-hadoop-yarn-server-hadoop-yarn-server-timelineservice-hbase-tests,org.apache.hadoop.yarn.server.timelineservice.storage.flow.TestHBaseStorageFlowRunCompaction.testWriteScanBatchLimit,java.lang.AssertionError, expected:<4> but was:<5>\\n
apache.hbase,hbase-hbase-procedure,org.apache.hadoop.hbase.procedure2.TestProcedureSkipPersistence.test,java.io.IOException,* Multiple error messages. *
apache.hbase,hbase-hbase-replication,org.apache.hadoop.hbase.replication.TestReplicationStateZKImpl.testReplicationQueues,org.apache.hadoop.hbase.replication.ReplicationException, Cannot get the list of peers\\n
apache.hbase,hbase-hbase-replication,org.apache.hadoop.hbase.replication.TestReplicationStateZKImpl.testRemovePeerForHFileRefs,org.apache.hadoop.hbase.replication.ReplicationException, Cannot get the list of peers\\n
apache.hbase,hbase-hbase-replication,org.apache.hadoop.hbase.replication.TestReplicationStateZKImpl.testReplicationPeers,org.apache.hadoop.hbase.replication.ReplicationException, Cannot get the list of peers\\n
apache.hbase,hbase-hbase-replication,org.apache.hadoop.hbase.replication.TestReplicationStateZKImpl.testPersistLogPositionAndSeqIdAtomically,org.apache.hadoop.hbase.replication.ReplicationException, Failed to get all queues (serverName=127.0.0.1;8000;10000)\\n
apache.hbase,hbase-hbase-replication,org.apache.hadoop.hbase.replication.TestReplicationStateZKImpl.testReplicationQueueStorage,org.apache.hadoop.hbase.replication.ReplicationException, Failed to get list of replicators\\n
apache.hbase,hbase-hbase-replication,org.apache.hadoop.hbase.replication.TestZKReplicationPeerStorage.test,java.lang.AssertionError, expected:<10> but was:<11>\\n
apache.hbase,hbase-hbase-replication,org.apache.hadoop.hbase.replication.TestReplicationStateZKImpl.testHfileRefsReplicationQueues,org.apache.hadoop.hbase.replication.ReplicationException, Cannot get the list of peers\\n
apache.hbase,hbase-hbase-zookeeper,org.apache.hadoop.hbase.zookeeper.TestInstancePending.test,java.lang.InterruptedException, sleep interrupted\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-cluster,org.apache.dubbo.rpc.cluster.support.ForkingClusterInvokerTest.testClearRpcContext,java.lang.AssertionError, set attachment failed!\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-cluster,org.apache.dubbo.rpc.cluster.support.AbstractClusterInvokerTest.testBindingAttachment,java.lang.AssertionError, set attachment failed!\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-cluster,org.apache.dubbo.rpc.cluster.StickyTest.testMethodStickyNoCheck,java.lang.AssertionError,
apache.incubator-dubbo,incubator-dubbo-dubbo-common,org.apache.dubbo.common.threadlocal.InternalThreadLocalTest.testSize,java.lang.AssertionError, size method is wrong!\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.AbstractInterfaceConfigTest.testLoadRegistries,java.lang.IllegalStateException, the temporary folder has not yet been created\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.AbstractInterfaceConfigTest.testListener,java.lang.IllegalStateException, the temporary folder has not yet been created\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.ReferenceConfigTest.testInjvm,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.validation.ValidationTest.testGenericValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.validation.ValidationTest.testProviderValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.cache.CacheTest.testCache,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-api,org.apache.dubbo.config.validation.ValidationTest.testValidation,java.lang.IllegalStateException,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-config-dubbo-config-spring,org.apache.dubbo.config.spring.beans.factory.annotation.ServiceAnnotationBeanPostProcessorTest.test,java.lang.IllegalStateException, Failed to load ApplicationContext\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-filter-dubbo-filter-cache,org.apache.dubbo.cache.support.jcache.JCacheFactoryTest.testJCacheGetExpired,java.lang.AssertionError, expected null; but was:<testValue>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-api,org.apache.dubbo.rpc.proxy.jdk.JdkProxyFactoryTest.testGetInvoker,java.lang.AssertionError,* Multiple error messages. *
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-api,org.apache.dubbo.rpc.proxy.javassist.JavassistProxyFactoryTest.testGetInvoker,java.lang.AssertionError, expected:<java.lang.Object@453da22c> but was:<aa>\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-dubbo,org.apache.dubbo.rpc.protocol.dubbo.DubboProtocolTest.testDubboProtocolWithMina,org.apache.dubbo.rpc.RpcException, Unsupported server type: mina; url: dubbo://127.0.0.1:9010/org.apache.dubbo.rpc.protocol.dubbo.support.DemoService?channel.readonly.sent=true&heartbeat=60000&server=mina\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-dubbo,org.apache.dubbo.rpc.protocol.dubbo.telnet.ListTelnetHandlerTest.testListService,org.apache.dubbo.rpc.RpcException, Fail to start server(url: dubbo://127.0.0.1:20885/demo?channel.readonly.sent=true&codec=dubbo&heartbeat=60000) Failed to bind NettyServer on /127.0.0.1:20885; cause: Address already in use\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-rpc-dubbo-rpc-dubbo,org.apache.dubbo.rpc.protocol.dubbo.telnet.ChangeTelnetHandlerTest.testChangePath,org.apache.dubbo.rpc.RpcException, Fail to start server(url: dubbo://127.0.0.1:20883/demo?channel.readonly.sent=true&codec=dubbo&heartbeat=60000) Failed to bind NettyServer on /127.0.0.1:20883; cause: Address already in use\\n
apache.incubator-dubbo,incubator-dubbo-dubbo-serialization-dubbo-serialization-fst,org.apache.dubbo.common.serialize.fst.FstObjectInputTest.testEmptyByteArrayForEmptyInput,java.lang.AssertionError, \\nExpected: is <0>\\n     but: was <123>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-core,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.singleQueryRun,java.lang.AssertionError, expected:<1> but was:<0>\\n
apache.jackrabbit-oak,jackrabbit-oak-oak-core,org.apache.jackrabbit.oak.plugins.index.property.OrderedPropertyIndexProviderTest.multipleQueryRuns,java.lang.AssertionError, \\nExpected: is <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n     but: was <[Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs; Ordered Index has been deprecated since Oak 1.1.8. Please replace the index definition ({}) with Lucene Property index and remove the index providers from the repository. See docs at http://jackrabbit.apache.org/oak/docs]>\\n
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr286DispatcherTest.testRender_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr286DispatcherTest.testProcessAction_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr168DispatcherTest.testRender_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
apache.struts,Struts-plugins-portlet,org.apache.struts2.portlet.dispatcher.Jsr168DispatcherTest.testProcessAction_ok,org.jmock.core.DynamicMockError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_full_collection_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_collection_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_map_key_value,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_map_key_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_index_and_multi_clustering_columns_slice,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_map_key_entry,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_index_and_clustering_column,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_index_and_clustering_column_slice,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.bugs.TestEntityWithCaseSensitivePKIT.should_dsl_select_with_token_value,java.lang.AssertionError, \\nExpecting actual not to be null\\n
doanduyhai.achilles,Achilles-integration-test-2_1,info.archinnov.achilles.it.TestEntityWithComplexIndices.should_query_using_simple_index,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_map_key_value_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_collection_index_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_map_key_index_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_full_collection_index_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-2_2,info.archinnov.achilles.it.TestEntityWithIndicesForJSON.should_query_using_map_key_entry_fromJSON,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_10,info.archinnov.achilles.it.TestEntityForGroupByIT.should_select_sum_group_by_partition_keys_and_one_clustering,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_10,info.archinnov.achilles.it.TestEntityForGroupByIT.should_select_sum_group_by_partition_keys,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_eq_non_tokenizer,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_like_non_tokenizer,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_contains,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_prefix_non_tokenizer,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_like,java.lang.AssertionError,* Multiple error messages. *
doanduyhai.achilles,Achilles-integration-test-3_7,info.archinnov.achilles.it.TestEntityWithSASIIndices.should_search_using_end_with,java.lang.AssertionError, \\nExpected size:<1> but was:<6> in:\\n<[info.archinnov.achilles.internals.entities.EntityWithSASIIndices@6b98a075; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@2e61d218; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@3569fc08; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@20b12f8a; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@e84a8e1; info.archinnov.achilles.internals.entities.EntityWithSASIIndices@2e554a3b]>\\n
dropwizard.dropwizard,dropwizard-dropwizard-e2e,com.example.app1.App1Test.customJsonProviderRoundtrip,java.lang.NullPointerException,
dropwizard.dropwizard,dropwizard-dropwizard-e2e,com.example.app1.App1Test.customJsonProvider,java.lang.NullPointerException,
dropwizard.dropwizard,dropwizard-dropwizard-e2e,com.example.app1.App1Test.customJsonProviderClient,java.lang.NullPointerException,
dropwizard.dropwizard,dropwizard-dropwizard-logging,io.dropwizard.logging.DefaultLoggingFactoryPrintErrorMessagesTest.testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut,java.lang.AssertionError,* Multiple error messages. *
dropwizard.dropwizard,dropwizard-dropwizard-logging,io.dropwizard.logging.DefaultLoggingFactoryTest.testConfigure,java.lang.AssertionError," \\nExpecting:\\n  <[]>\\nto contain only:\\n  <[""DEBUG com.example.newApp: New application debug log"";\\n    ""INFO  com.example.newApp: New application info log""]>\\nbut could not find the following elements:\\n  <[""DEBUG com.example.newApp: New application debug log"";\\n    ""INFO  com.example.newApp: New application info log""]>\\n\\n"
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.reg.zookeeper.ZookeeperRegistryCenterModifyTest.assertPersistEphemeralSequential,java.lang.AssertionError, \\nExpected: is <2>\\n     but: was <4>\\n
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.event.rdb.JobEventRdbSearchTest.assertFindJobExecutionEventsWithTime,java.lang.AssertionError,* Multiple error messages. *
elasticjob.elastic-job-lite,elastic-job-lite-elastic-job-lite-core,io.elasticjob.lite.event.rdb.JobEventRdbSearchTest.assertFindJobStatusTraceEventsWithTime,java.lang.AssertionError,* Multiple error messages. *
jfree.jfreechart,jfreechart-,org.jfree.data.time.DayTest.testParseDay,java.lang.AssertionError, expected:<37256> but was:<37255>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.deleteWithMappedQueryParams,java.lang.AssertionError, expected:<user> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.headWithVaragsQueryParams,java.lang.AssertionError, expected:<user> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.putWithMappedQueryParams,java.lang.AssertionError, expected:<user> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.postWithNumericQueryParams,java.lang.AssertionError, expected:<2> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.getWithEscapedMappedQueryParams,java.lang.AssertionError, expected:<us er> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.deleteWithEscapedVarargsQueryParams,java.lang.AssertionError, expected:<us er> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.postWithEscapedVarargsQueryParams,java.lang.AssertionError, expected:<us er> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.deleteWithVarargsQueryParams,java.lang.AssertionError, expected:<user> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.headWithEscapedMappedQueryParams,java.lang.AssertionError, expected:<us er> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.headWithMappedQueryParams,java.lang.AssertionError, expected:<user> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.getWithVarargsQueryParams,java.lang.AssertionError, expected:<user> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.putWithEscapedVarargsQueryParams,java.lang.AssertionError, expected:<us er> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.singleSslSocketFactory,java.lang.ClassCastException, sun.net.www.protocol.http.HttpURLConnection cannot be cast to javax.net.ssl.HttpsURLConnection\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.headWithEscapedVarargsQueryParams,java.lang.AssertionError, expected:<us er> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.postWithVaragsQueryParams,java.lang.AssertionError, expected:<user> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.putWithEscapedMappedQueryParams,java.lang.AssertionError, expected:<us er> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.basicProxyAuthentication,HttpRequestException, java.io.IOException\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.postWithMappedQueryParams,java.lang.AssertionError, expected:<user> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.verifierAccepts,java.lang.ClassCastException, sun.net.www.protocol.http.HttpURLConnection cannot be cast to javax.net.ssl.HttpsURLConnection\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.getWithMappedQueryParams,java.lang.AssertionError, expected:<user> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.deleteWithEscapedMappedQueryParams,java.lang.AssertionError, expected:<us er> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.putWithVarargsQueryParams,java.lang.AssertionError, expected:<user> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.singleVerifier,java.lang.ClassCastException, sun.net.www.protocol.http.HttpURLConnection cannot be cast to javax.net.ssl.HttpsURLConnection\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.getWithEscapedVarargsQueryParams,java.lang.AssertionError, expected:<us er> but was:<null>\\n
kevinsawicki.http-request,http-request-lib,com.github.kevinsawicki.http.HttpRequestTest.postWithEscapedMappedQueryParams,java.lang.AssertionError, expected:<us er> but was:<null>\\n
knightliao.disconf,disconf-disconf-client,com.baidu.disconf.client.test.DisconfMgrTestCase.demo,java.net.SocketTimeoutException, Read timed out\\n
looly.hutool,hutool-hutool-cron,cn.hutool.cron.test.CronTest.matchAllTest,java.lang.AssertionError,
oryxproject.oryx,oryx-framework-oryx-common,com.cloudera.oryx.common.io.IOUtilsTest.testDistinctFreePorts,java.lang.AssertionError, expected:<10> but was:<9>\\n
querydsl.querydsl,querydsl-querydsl-hibernate-search,com.querydsl.hibernate.search.SearchQueryTest.listResults,java.lang.AssertionError,* Multiple error messages. *
querydsl.querydsl,querydsl-querydsl-hibernate-search,com.querydsl.hibernate.search.SearchQueryTest.count,java.lang.AssertionError,* Multiple error messages. *
querydsl.querydsl,querydsl-querydsl-hibernate-search,com.querydsl.hibernate.search.SearchQueryTest.paging,java.lang.AssertionError,* Multiple error messages. *
spotify.helios,helios-helios-testing,com.spotify.helios.testing.HeliosSoloDeploymentTest.testUndeployLeftoverJobs,java.lang.StackOverflowError,
spring-projects.spring-boot,spring-boot-spring-boot-project-spring-boot-actuator-autoconfigure,org.springframework.boot.actuate.autoconfigure.cloudfoundry.servlet.CloudFoundryMvcWebEndpointIntegrationTests.operationWithSecurityInterceptorSuccess,java.lang.AssertionError,* Multiple error messages. *
spring-projects.spring-boot,spring-boot-spring-boot-project-spring-boot-actuator-autoconfigure,org.springframework.boot.actuate.autoconfigure.cloudfoundry.servlet.CloudFoundryMvcWebEndpointIntegrationTests.linksToOtherEndpointsWithFullAccess,java.lang.AssertionError,* Multiple error messages. *
spring-projects.spring-boot,spring-boot-spring-boot-project-spring-boot-actuator-autoconfigure,org.springframework.boot.actuate.autoconfigure.cloudfoundry.servlet.CloudFoundryMvcWebEndpointIntegrationTests.operationWithSecurityInterceptorForbidden,java.lang.AssertionError,* Multiple error messages. *
spring-projects.spring-boot,spring-boot-spring-boot-project-spring-boot-actuator-autoconfigure,org.springframework.boot.actuate.autoconfigure.cloudfoundry.servlet.CloudFoundryMvcWebEndpointIntegrationTests.linksToOtherEndpointsWithRestrictedAccess,java.lang.AssertionError,* Multiple error messages. *
spring-projects.spring-boot,spring-boot-spring-boot-project-spring-boot-actuator-autoconfigure,org.springframework.boot.actuate.autoconfigure.cloudfoundry.reactive.CloudFoundryWebFluxEndpointIntegrationTests.operationWithSecurityInterceptorSuccess,org.springframework.boot.actuate.autoconfigure.cloudfoundry.CloudFoundryAuthorizationException, invalid-token\\n
spring-projects.spring-boot,spring-boot-spring-boot-project-spring-boot-actuator-autoconfigure,org.springframework.boot.actuate.autoconfigure.cloudfoundry.reactive.CloudFoundryWebFluxEndpointIntegrationTests.linksToOtherEndpointsWithFullAccess,org.springframework.boot.actuate.autoconfigure.cloudfoundry.CloudFoundryAuthorizationException, invalid-token\\n
spring-projects.spring-boot,spring-boot-spring-boot-project-spring-boot-actuator-autoconfigure,org.springframework.boot.actuate.autoconfigure.cloudfoundry.reactive.CloudFoundryWebFluxEndpointIntegrationTests.linksToOtherEndpointsWithRestrictedAccess,org.springframework.boot.actuate.autoconfigure.cloudfoundry.CloudFoundryAuthorizationException, invalid-token\\n
spring-projects.spring-boot,spring-boot-spring-boot-project-spring-boot-actuator-autoconfigure,org.springframework.boot.actuate.autoconfigure.cloudfoundry.reactive.CloudFoundryWebFluxEndpointIntegrationTests.operationWithSecurityInterceptorForbidden,org.springframework.boot.actuate.autoconfigure.cloudfoundry.CloudFoundryAuthorizationException, invalid-token\\n
spring-projects.spring-boot,spring-boot-spring-boot-project-spring-boot-test,org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListenerTests.test002,org.opentest4j.AssertionFailedError," \\nExpecting:\\n <null>\\nto be equal to:\\n <""none"">\\nbut was not.\\n"
square.retrofit,retrofit-retrofit-adapters-rxjava,retrofit2.adapter.rxjava.CompletableThrowingTest.bodyThrowingInOnErrorDeliveredToPlugin,rx.exceptions.OnErrorFailedException, Error occurred attempting to subscribe [3 exceptions occurred. ] and then again while trying to pass to onError.\\n
square.retrofit,retrofit-retrofit-adapters-rxjava,retrofit2.adapter.rxjava.CompletableThrowingSafeSubscriberTest.throwingInOnCompleteDeliveredToPlugin,java.lang.IllegalStateException, Another strategy was already registered: rx.plugins.RxJavaPlugins$1@5f058f00\\n
square.retrofit,retrofit-retrofit-adapters-rxjava,retrofit2.adapter.rxjava.ObservableThrowingTest.responseThrowingInOnCompleteDeliveredToPlugin,java.lang.IllegalStateException, Another strategy was already registered: rx.plugins.RxJavaPlugins$1@6379eb\\n
square.retrofit,retrofit-retrofit-adapters-rxjava,retrofit2.adapter.rxjava.CancelDisposeTest.cancelDoesNotDispose,java.net.SocketException, Socket closed\\njava.lang.AssertionError\\n
square.retrofit,retrofit-retrofit-adapters-rxjava,retrofit2.adapter.rxjava.SingleThrowingTest.bodyThrowingInOnSuccessDeliveredToPlugin,java.lang.IllegalStateException, Another strategy was already registered: rx.plugins.RxJavaPlugins$1@4a22f9e2\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.issues.Issue677Test.testIssue,java.lang.AssertionError, webSocket.isClosed()\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase7,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase4,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase9,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase10,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase8,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase3,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase11,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase6,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase2,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.issues.Issue580Test.runNoCloseBlockingTestScenario2,java.lang.AssertionError, Found 3 zombie thread(s) \\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase10,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase4,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase2,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase14,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase1,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase8,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.issues.Issue580Test.runNoCloseBlockingTestScenario8,java.lang.AssertionError,* Multiple error messages. *
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase11,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase17,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase5,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.issues.Issue580Test.runNoCloseBlockingTestScenario3,java.lang.AssertionError, Found 3 zombie thread(s) \\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase3,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase13,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase0,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.issues.Issue580Test.runNoCloseBlockingTestScenario4,java.lang.AssertionError,* Multiple error messages. *
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.issues.Issue580Test.runNoCloseBlockingTestScenario0,java.lang.AssertionError, Found 3 zombie thread(s) \\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.issues.Issue580Test.runNoCloseBlockingTestScenario5,java.lang.AssertionError,* Multiple error messages. *
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase16,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.misc.OpeningHandshakeRejectionTest.testHandshakeRejectionTestCase6,java.lang.AssertionError, Error\\n
tootallnate.java-websocket,Java-WebSocket-,org.java_websocket.protocols.ProtoclHandshakeRejectionTest.testHandshakeRejectionTestCase9,java.lang.AssertionError, Error\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testLookup,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.subsystem.NamingSubsystemTestCase.testCompositeBindingOps,java.lang.RuntimeException, java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.subsystem.NamingSubsystemTestCase.testSubsystem,java.lang.RuntimeException, java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testBindReferenceable,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingEventCoordinatorTestCase.testFireOneLevelEvent,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testListWithContinuation,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.WritableServiceBasedNamingStoreTestCase.testPermissions,java.lang.ExceptionInInitializerError,
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.WritableServiceBasedNamingStoreTestCase.testRebind,javax.naming.NamingException, WFLYNAM0062: Failed to lookup test [Root exception is java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager]\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingEventCoordinatorTestCase.testFireObjectEvent,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testLookupNameNotFound,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.WritableServiceBasedNamingStoreTestCase.testBindNested,javax.naming.NamingException, WFLYNAM0062: Failed to lookup nested/test [Root exception is java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager]\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testRebindReferenceable,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testUnbind,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testListNameNotFound,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.ServiceBasedNamingStoreTestCase.testListBindings,javax.naming.NamingException, WFLYNAM0062: Failed to lookup  [Root exception is java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager]\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testListBindingsWithContinuation,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.WritableServiceBasedNamingStoreTestCase.testBind,javax.naming.NamingException, WFLYNAM0062: Failed to lookup test [Root exception is java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager]\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testLookupEmptyName,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.InitialContextTestCase.testRegisterURLSchemeHandler,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.subsystem.NamingSubsystemTestCase.testCompositeBindingUpdate,java.lang.RuntimeException, java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testLookupWitResolveResult,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testListBindings,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingEventCoordinatorTestCase.testFireAllEvent,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testLookupLink,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testLookupContextLink,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.ServiceBasedNamingStoreTestCase.testLookupBindingUsingNestedContext,javax.naming.NamingException, WFLYNAM0062: Failed to lookup foo/bar/baz/TestBean [Root exception is java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager]\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.InitialContextFactoryTestCase.testInitialFactory,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.InitialContextFactoryTestCase.testJavaContext,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testBind,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.ServiceBasedNamingStoreTestCase.testStoredContext,javax.naming.NamingException, WFLYNAM0062: Failed to lookup foo-stored/again/blah/blah2 [Root exception is java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager]\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testLookupReference,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.subsystem.NamingSubsystemTestCase.testOnlyExternalContextAllowsCache,java.lang.RuntimeException, java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.ObjectFactoryTestCase.testBindAndRetrieveObjectFactoryFromNamingContext,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testRebind,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.ServiceBasedNamingStoreTestCase.testLookupBinding,javax.naming.NamingException, WFLYNAM0062: Failed to lookup foo/bar [Root exception is java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager]\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testList,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testListBindingsNameNotFound,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingEventCoordinatorTestCase.testFireSubTreeEvent,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingEventCoordinatorTestCase.testFireMultiLevelEvent,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testLookupWithContinuation,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.ObjectFactoryTestCase.testBindAndRetrieveObjectFactoryFromInitialContext,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.subsystem.NamingSubsystemTestCase.testRejectionsEAP7,java.lang.RuntimeException, java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.subsystem.NamingSubsystemTestCase.testRejectionsEAP6,java.lang.RuntimeException, java.lang.NoClassDefFoundError: Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-naming,org.jboss.as.naming.NamingContextTestCase.testCreateSubcontext,java.lang.NoClassDefFoundError, Could not initialize class org.wildfly.security.manager.WildFlySecurityManager\\n
wildfly.wildfly,wildfly-security-subsystem,org.jboss.as.security.SecurityDomainModelv12UnitTestCase.testSubsystem,java.lang.AssertionError, Subsystem boot failed!\\n
wildfly.wildfly,wildfly-testsuite-integration-web,org.jboss.as.test.integration.web.sharedsession.SharedSessionTestCase.testSharedSessionsOneEar,java.lang.UnsupportedOperationException,* Multiple error messages. *
wildfly.wildfly,wildfly-testsuite-integration-web,org.jboss.as.test.integration.web.sharedsession.SharedSessionTestCase.testSharedSessionsDoNotInterleave,java.lang.UnsupportedOperationException,* Multiple error messages. *
wildfly.wildfly,wildfly-testsuite-integration-web,org.jboss.as.test.integration.web.sharedsession.SharedSessionTestCase.testNotSharedSessions,java.lang.UnsupportedOperationException,* Multiple error messages. *
wildfly.wildfly,wildfly-testsuite-integration-web,org.jboss.as.test.integration.web.jsp.taglib.external.ExternalTagLibTestCase.testExternalAndInternalTagLib,java.lang.IllegalStateException, Neither -Dmodule.path nor -Djboss.home were set\\n
wro4j.wro4j,wro4j-wro4j-core,ro.isdc.wro.model.resource.support.naming.TestHashEncoderNamingStrategy.cannotAcceptNullStream,java.lang.AssertionError, expected:<0> but was:<3>\\n
wro4j.wro4j,wro4j-wro4j-core,ro.isdc.wro.model.resource.support.naming.TestDefaultHashEncoderNamingStrategy.cannotAcceptNullStream,java.lang.AssertionError, expected:<0> but was:<3>\\n
wro4j.wro4j,wro4j-wro4j-core,ro.isdc.wro.model.resource.support.change.TestResourceWatcher.cannotCheckNullCacheEntry,java.lang.AssertionError, expected:<0> but was:<3>\\n
wro4j.wro4j,wro4j-wro4j-core,ro.isdc.wro.model.resource.support.TestDefaultResourceAuthorizationManager.shouldContainOnlyOneResourceWhenSameIsAddedTwice,java.lang.AssertionError, expected:<0> but was:<3>\\n
wro4j.wro4j,wro4j-wro4j-core,ro.isdc.wro.util.TestWroUtil.shouldJoinTwoPaths,java.lang.AssertionError, expected:<0> but was:<3>\\n
wro4j.wro4j,wro4j-wro4j-core,ro.isdc.wro.cache.support.TestSynchronizedCacheStrategyDecorator.shouldInvokeLoadTwoTimesForDifferentKeys,java.lang.AssertionError, expected:<0> but was:<3>\\n
wro4j.wro4j,wro4j-wro4j-core,ro.isdc.wro.model.resource.support.change.TestResourceChangeInfo.cannotCheckChangeForNullGroupName,java.lang.AssertionError, expected:<0> but was:<3>\\n
wro4j.wro4j,wro4j-wro4j-extensions,ro.isdc.wro.extensions.processor.TestRubySassCssProcessor.shouldBeThreadSafeWhenInitializingProcessor,java.util.concurrent.ExecutionException, java.lang.RuntimeException: ro.isdc.wro.WroRuntimeException: java.util.ConcurrentModificationException\\n
wro4j.wro4j,wro4j-wro4j-extensions,ro.isdc.wro.extensions.processor.TestBourbonCssProcessor.shouldBeThreadSafe,java.util.concurrent.ExecutionException, java.lang.RuntimeException: ro.isdc.wro.WroRuntimeException: java.util.ConcurrentModificationException\\n
extended,java-cas-client-cas-client-core,org.jasig.cas.client.validation.AssertionImplTests.testAssertionValidity,junit.framework.AssertionFailedError, null\\n
extended,c2mon-c2mon-daq-c2mon-daq-core,cern.c2mon.daq.filter.dynamic.DiffTimeDeadbandActivatorTest.testNoActivationOnFirstRecord,junit.framework.AssertionFailedError,
extended,c2mon-c2mon-server-c2mon-server-common,cern.c2mon.server.common.republisher.RepublisherImplTest.testMultipleExceptions,java.lang.AssertionError, expected:<0> but was:<1>\\n
extended,c2mon-c2mon-server-c2mon-server-common,cern.c2mon.server.common.republisher.RepublisherImplTest.testMultiplePublicationsWithExceptions,java.lang.AssertionError, expected:<0> but was:<1>\\n
extended,vertx-completable-future,me.escoffier.vertx.completablefuture.VertxCompletableFutureTest.testAcceptEitherAsyncWithExecutor,java.lang.AssertionError, Not equals : 42 != 1\\n
extended,excelastic,com.codingchili.TestWriter.shouldWriteToElasticPort,AnnotatedConnectException,* Multiple error messages. *
extended,rxjava2-extras,com.github.davidmoten.rx2.internal.flowable.FlowableServerSocketTest.testLoad,java.lang.AssertionError, Not completed (latch = 0; values = 0; errors = 1; completions = 0)\\n
extended,esper-examples-rfidassetzone,com.espertech.esper.example.rfidassetzone.TestLRMovingSimMain.testSim,java.lang.RuntimeException, Invalid result for listener; expected split group\\n
extended,esper-runtime,com.espertech.esper.runtime.internal.schedulesvcimpl.TestSchedulingServiceImpl.testTrigger,junit.framework.AssertionFailedError, expected:<1> but was:<6>\\n
extended,hsac-fitnesse-fixtures,nl.hsac.fitnesse.fixture.slim.FileFixtureTest.testDelete,java.lang.AssertionError, Should not happen: message:<<Unable to find: /home/awshi2/fhoeben/hsac-fitnesse-fixtures/src/test/resources/temp-copy.txt>>\\n
extended,fluent-logger-java,org.fluentd.logger.TestFluentLogger.testReconnection,java.lang.AssertionError, \\n
extended,redpipe-redpipe-engine,net.redpipe.engine.swagger.SwaggerApiTest.checkSwagger,java.lang.OutOfMemoryError, unable to create new native thread\\n
extended,redpipe-redpipe-templating-freemarker,net.redpipe.templating.freemarker.ApiTest.checkTemplateNegociationText,java.lang.OutOfMemoryError, unable to create new native thread\\n
extended,GoodData-CL-connector,com.gooddata.csv.DataTypeGuessTest.testIsDate,java.lang.NullPointerException,
extended,spring-data-ebean,org.springframework.data.ebean.repository.UserRepositoryIntegrationTest.deleteById,java.util.NoSuchElementException, No value present\\n
extended,delight-nashorn-sandbox,delight.nashornsandbox.TestMemoryLimit.test_no_abuse,junit.framework.AssertionFailedError, No exception should be thrown\\n
extended,delight-nashorn-sandbox,delight.nashornsandbox.TestGetFunction.test,delight.nashornsandbox.exceptions.ScriptMemoryAbuseException, Script used more than the allowed [51200 B] of memory.\\n
extended,jmeter-maven-plugin,com.lazerycode.jmeter.json.TestConfigTest.createConfigFromResourceFile,java.lang.AssertionError," \\nExpected: is ""{\\n  \""resultFilesLocations\"" : [];\\n  \""resultsOutputIsCSVFormat\"" : false;\\n  \""someOtherElement\"": \""foo\""\\n}""\\n     but: was ""{\\n  \""resultFilesLocations\"" : [];\\n  \""resultsOutputIsCSVFormat\"" : false;\\n  \""generateReports\"": false\\n}""\\n"
extended,jnr-posix,jnr.posix.SpawnTest.inputPipe,java.lang.AssertionError,* Multiple error messages. *
extended,jnr-posix,jnr.posix.SpawnTest.outputPipe,java.lang.AssertionError,* Multiple error messages. *
extended,db-scheduler,com.github.kagkarlsson.scheduler.compatibility.HsqlCompatibilityTest.test_compatibility,java.lang.AssertionError,* Multiple error messages. *
extended,db-scheduler,com.github.kagkarlsson.scheduler.WaiterTest.should_wait_until_woken,java.lang.AssertionError,* Multiple error messages. *
extended,db-scheduler,com.github.kagkarlsson.scheduler.SchedulerTest.scheduler_should_execute_rescheduled_task_when_exactly_due,java.lang.AssertionError, \\nExpected: is <1>\\n     but: was <0>\\n
extended,marine-api,net.sf.marineapi.ais.parser.AISMessageFactoryTest.testCreateWithTwo,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.event.AbstractAISMessageListenerTest.testSequenceListenerWithIncorrectOrder,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.event.AbstractAISMessageListenerTest.testGenericsListenerDefaultConstructorThrows,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.event.AbstractAISMessageListenerTest.testGenericsListener,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.event.AbstractAISMessageListenerTest.testSequenceListenerWithMixedOrder,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.event.AbstractAISMessageListenerTest.testConstructor,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.event.AbstractAISMessageListenerTest.testOnMessageWithExpectedMessage,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.event.AbstractAISMessageListenerTest.testSequenceListener,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.parser.AISMessageFactoryTest.testCreate,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.parser.AISMessageFactoryTest.testCreateWithIncorrectOrder,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.event.AbstractAISMessageListenerTest.testParametrizedConstructor,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,marine-api,net.sf.marineapi.ais.event.AbstractAISMessageListenerTest.testBasicListenerWithUnexpectedMessage,net.sf.marineapi.nmea.parser.UnsupportedSentenceException, Parser for type 'VDM' not found\\n
extended,spring-cloud-zuul-ratelimit-spring-cloud-zuul-ratelimit-tests-bucket4j-infinispan,com.marcosbarbero.tests.it.Bucket4jInfinispanApplicationTestIT.testExceedingQuotaCapacityRequest,java.lang.AssertionError,* Multiple error messages. *
extended,timely-server,timely.store.iterators.TimeSeriesGroupingIteratorTest.testManySparseTimeSeries,java.lang.AssertionError,* Multiple error messages. *
extended,sos-20-modulith,example.sos.modulith.orders.EmailNotificationTest.completingAnOrderUpdatesInventory,java.lang.AssertionError,* Multiple error messages. *
extended,Chronicle-Wire,net.openhft.chronicle.wire.TextWireTest.testSingleQuote,java.lang.ClassCastException,* Multiple error messages. *
extended,openpojo,com.openpojo.validation.test.impl.SetterTesterTest.shouldSuccessfullyValidateEvenIfLoggingFails,java.lang.AssertionError, \\nExpected: is <1>\\n     but: was <0>\\n
extended,openpojo,com.openpojo.issues.issue112.IssueTest.shouldNotFail,java.lang.AssertionError, \\nExpected: is <1>\\n     but: was <0>\\n
extended,openpojo,com.openpojo.reflection.java.bytecode.asm.ASMServiceEnd2EndTest.shouldInvokeUsingConstructorArgs,com.openpojo.reflection.exception.ReflectionException, Failed to create parameters to pass to constructor for class [com.openpojo.reflection.java.bytecode.asm.sample.AbstractClassWithConstructorArgs] using constructor [PojoMethodImpl [constructor=com.openpojo.reflection.java.bytecode.asm.sample.AbstractClassWithConstructorArgs args=[class java.lang.String; boolean; byte; char; double; float; int; long; short; class [I; class [Ljava.lang.String;; interface java.util.List] return=class com.openpojo.reflection.java.bytecode.asm.sample.AbstractClassWithConstructorArgs]]\\n
extended,openpojo,com.openpojo.reflection.java.bytecode.ByteCodeFactoryTest.onlyValidConstructorsOverwritten,com.openpojo.reflection.java.bytecode.asm.ASMNotLoadedException, Incorrect version of ASM found; expected versions between [5.0 and less than 7.0] found [null]\\n
extended,openpojo,com.openpojo.reflection.java.bytecode.ByteCodeFactoryTest.givenAnAbstractClassWithGenericConstructorShouldConstruct,com.openpojo.reflection.java.bytecode.asm.ASMNotLoadedException, Incorrect version of ASM found; expected versions between [5.0 and less than 7.0] found [null]\\n
extended,openpojo,com.openpojo.reflection.java.bytecode.ByteCodeFactoryTest.givenAnAbstractClassWithAnAbstractMethodShouldReturnAnInstance,com.openpojo.reflection.java.bytecode.asm.ASMNotLoadedException, Incorrect version of ASM found; expected versions between [5.0 and less than 7.0] found [null]\\n
extended,openpojo,com.openpojo.reflection.java.bytecode.ByteCodeFactoryTest.givenAnEmptyAbstractClassShouldReturnImplementationClass,com.openpojo.reflection.java.bytecode.asm.ASMNotLoadedException, Incorrect version of ASM found; expected versions between [5.0 and less than 7.0] found [null]\\n
extended,openpojo,com.openpojo.reflection.java.bytecode.ByteCodeFactoryTest.givenAnAbstractClassWithConstructorShouldConstruct,com.openpojo.reflection.java.bytecode.asm.ASMNotLoadedException, Incorrect version of ASM found; expected versions between [5.0 and less than 7.0] found [null]\\n
extended,openpojo,com.openpojo.reflection.java.bytecode.ByteCodeFactoryTest.endToEndTest,com.openpojo.reflection.exception.ReflectionException, Failed to create parameters to pass to constructor for class [com.openpojo.reflection.java.bytecode.sample.ACompleteAbstractClass] using constructor [PojoMethodImpl [constructor=com.openpojo.reflection.java.bytecode.sample.ACompleteAbstractClass args=[class java.lang.String; class java.lang.Integer; interface java.util.List] return=class com.openpojo.reflection.java.bytecode.sample.ACompleteAbstractClass]]\\n
extended,openpojo,com.openpojo.reflection.java.bytecode.ByteCodeFactoryTest.givenTheSameClassShouldReturnSameGeneratedClass,com.openpojo.reflection.java.bytecode.asm.ASMNotLoadedException, Incorrect version of ASM found; expected versions between [5.0 and less than 7.0] found [null]\\n
extended,Aletheia-aletheia-core,com.outbrain.aletheia.SampleDomainClassDatumTest.test_avro_route,java.lang.AssertionError,* Multiple error messages. *
extended,Aletheia-aletheia-core,com.outbrain.aletheia.SampleDomainClassDatumTest.test_json_route,java.lang.AssertionError,* Multiple error messages. *
extended,Aletheia-aletheia-core,com.outbrain.aletheia.SampleDomainClassDatumTest.test_multiple_routes,java.lang.AssertionError,* Multiple error messages. *
extended,Aletheia-aletheia-core,com.outbrain.aletheia.SampleDomainClassDatumTest.testDatumRoutes,java.lang.AssertionError,* Multiple error messages. *
extended,junit-quickcheck-guava,com.pholser.junit.quickcheck.guava.generator.FunctionPropertyParameterTypesTest.arrayOfFunction,java.lang.AssertionError, expected:<100> but was:<0>\\n
extended,pippo-pippo-session-parent-pippo-session-mongodb,ro.pippo.session.mongodb.MongoDBSessionDataStorageTest.testCreate,java.lang.IllegalStateException, Couldn't kill mongod process!\\n\\n----------------------------------------------------\\nSomething bad happend. We couldn't kill mongod process; and tried a lot.\\nIf you want this problem solved you can help us if you open a new issue.\\n\\nFollow this link:\\nhttps://github.com/flapdoodle-oss/de.flapdoodle.embed.mongo/issues\\n\\nThank you:)\\n----------------------------------------------------\\n\\n\\n
extended,pippo-pippo-session-parent-pippo-session-mongodb,ro.pippo.session.mongodb.MongoDBSessionDataStorageTest.testDelete,java.lang.IllegalStateException, Couldn't kill mongod process!\\n\\n----------------------------------------------------\\nSomething bad happend. We couldn't kill mongod process; and tried a lot.\\nIf you want this problem solved you can help us if you open a new issue.\\n\\nFollow this link:\\nhttps://github.com/flapdoodle-oss/de.flapdoodle.embed.mongo/issues\\n\\nThank you:)\\n----------------------------------------------------\\n\\n\\n
extended,pippo-pippo-session-parent-pippo-session-mongodb,ro.pippo.session.mongodb.MongoDBSessionDataStorageTest.testSave,java.lang.IllegalStateException, Couldn't kill mongod process!\\n\\n----------------------------------------------------\\nSomething bad happend. We couldn't kill mongod process; and tried a lot.\\nIf you want this problem solved you can help us if you open a new issue.\\n\\nFollow this link:\\nhttps://github.com/flapdoodle-oss/de.flapdoodle.embed.mongo/issues\\n\\nThank you:)\\n----------------------------------------------------\\n\\n\\n
extended,pippo-pippo-session-parent-pippo-session-mongodb,ro.pippo.session.mongodb.MongoDBSessionDataStorageTest.testGet,java.lang.IllegalStateException, Couldn't kill mongod process!\\n\\n----------------------------------------------------\\nSomething bad happend. We couldn't kill mongod process; and tried a lot.\\nIf you want this problem solved you can help us if you open a new issue.\\n\\nFollow this link:\\nhttps://github.com/flapdoodle-oss/de.flapdoodle.embed.mongo/issues\\n\\nThank you:)\\n----------------------------------------------------\\n\\n\\n
extended,recast4j-detourtilecache,org.recast4j.detour.tilecache.TileCacheTest.testPerformance,java.lang.OutOfMemoryError, unable to create new native thread\\n
extended,noxy-noxy-discovery-zookeeper,com.spinn3r.noxy.discovery.zookeeper.ZKTest.testDiscoveryListener,com.spinn3r.artemis.init.resource_mutexes.ResourceMutexException,ExhaustedException: Unable to allocate port mutex between range 64149 and 64300\\n
extended,noxy-noxy-discovery-zookeeper,com.spinn3r.noxy.discovery.zookeeper.ZKTest.testMembershipJoinAndLeave,com.spinn3r.artemis.init.resource_mutexes.ResourceMutexException,ExhaustedException: Unable to allocate port mutex between range 64149 and 64300\\n
extended,noxy-noxy-reverse,com.spinn3r.noxy.reverse.ReverseProxyServiceTest.testRequestMetaForSuccessfulRequest,java.net.BindException,* Multiple error messages. *
extended,spring-cloud-aws-spring-cloud-aws-context,org.springframework.cloud.aws.cache.config.xml.CacheBeanDefinitionParserTest.parseInternal_cacheConfigWithExpiration_returnsConfiguredCacheThatRespectExpiration,org.springframework.beans.factory.BeanCreationException, Error creating bean with name 'regionProvider': Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cloud.aws.core.region.StaticRegionProvider]: Constructor threw exception; nested exception is java.lang.IllegalArgumentException: The region 'eu-wast-1' is not a valid region!\\n
extended,spring-data-envers,org.springframework.data.envers.repository.support.QueryDslRepositoryIntegrationTests.testWithRevisions,org.hibernate.exception.ConstraintViolationException," could not execute statement]\\norg.springframework.dao.DataIntegrityViolationException: could not execute statement; SQL [n/a]; constraint [""FKMPDN78BJWY8S6BJ94CYYNTJ9N: PUBLIC.LICENSE_COUNTRY FOREIGN KEY(LAENDER_ID) REFERENCES PUBLIC.COUNTRY(ID) (6)""; SQL statement:\\ndelete from Country where id=? [23503-166]]; nested exception is org.hibernate.exception.ConstraintViolationException: could not execute statement\\n"
extended,spring-data-envers,org.springframework.data.envers.repository.support.QueryDslRepositoryIntegrationTests.testWithQueryDsl,org.hibernate.exception.ConstraintViolationException," could not execute statement]\\norg.springframework.dao.DataIntegrityViolationException: could not execute statement; SQL [n/a]; constraint [""FKMPDN78BJWY8S6BJ94CYYNTJ9N: PUBLIC.LICENSE_COUNTRY FOREIGN KEY(LAENDER_ID) REFERENCES PUBLIC.COUNTRY(ID) (6)""; SQL statement:\\ndelete from Country where id=? [23503-166]]; nested exception is org.hibernate.exception.ConstraintViolationException: could not execute statement\\n"
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap11WebServiceTemplateIntegrationTest.marshalSendAndReceiveResponse,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap12WebServiceTemplateIntegrationTest.marshalSendAndReceiveNoResponse,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap12WebServiceTemplateIntegrationTest.sendSourceAndReceiveToResult,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap11WebServiceTemplateIntegrationTest.sendSourceAndReceiveToResultNoResponse,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap12WebServiceTemplateIntegrationTest.sendSourceAndReceiveToResultNoResponse,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap12WebServiceTemplateIntegrationTest.marshalSendAndReceiveResponse,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap12WebServiceTemplateIntegrationTest.receiverFault,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap12WebServiceTemplateIntegrationTest.attachment,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap11WebServiceTemplateIntegrationTest.notFound,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap11WebServiceTemplateIntegrationTest.attachment,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap11WebServiceTemplateIntegrationTest.faultNonCompliant,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap12WebServiceTemplateIntegrationTest.notFound,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap11WebServiceTemplateIntegrationTest.marshalSendAndReceiveNoResponse,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap12WebServiceTemplateIntegrationTest.senderFault,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-core,org.springframework.ws.client.core.AxiomNonStreamingSoap11WebServiceTemplateIntegrationTest.fault,org.springframework.ws.client.WebServiceIOException, I/O error: Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused)\\n
extended,spring-ws-spring-ws-security,org.springframework.ws.soap.security.xwss.callback.SpringDigestPasswordValidationCallbackHandlerTest.testAuthenticateUserDigestUserNotFound,java.lang.AssertionError, Authentication created expected null; but was:<org.springframework.security.authentication.UsernamePasswordAuthenticationToken@5ef582e1: Principal: WSUsernameTokenPrincipalImpl:  Ernie; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_1>\\n
extended,spring-ws-spring-ws-security,org.springframework.ws.soap.security.xwss.callback.SpringDigestPasswordValidationCallbackHandlerTest.testAuthenticateUserDigestValidInvalid,java.lang.AssertionError, Authentication created expected null; but was:<org.springframework.security.authentication.UsernamePasswordAuthenticationToken@5ef582e1: Principal: WSUsernameTokenPrincipalImpl:  Ernie; Credentials: [PROTECTED]; Authenticated: true; Details: null; Granted Authorities: ROLE_1>\\n
extended,aismessages,dk.tbsalling.aismessages.nmea.NMEAMessageHandlerTest.canHandleUnfragmentedMessageReceived,java.lang.NullPointerException,
extended,aismessages,dk.tbsalling.aismessages.nmea.NMEAMessageHandlerTest.canHandleFragmentedMessageReceived,java.lang.NullPointerException,* Multiple error messages. *
extended,vertx-mqtt,io.vertx.mqtt.test.server.MqttServerClientIdentifierTest.testValidClientIdentifier,java.util.concurrent.TimeoutException,
extended,vertx-mqtt,io.vertx.mqtt.test.server.MqttServerConnectionTest.connectionAlreadyAccepted,java.util.concurrent.TimeoutException,
extended,vertx-mqtt,io.vertx.mqtt.test.server.MqttServerConnectionTest.accepted,java.util.concurrent.TimeoutException,
extended,vertx-mqtt,io.vertx.mqtt.test.server.MqttServerConnectionTest.noConnectSent,java.util.concurrent.TimeoutException, Timed out\\n
extended,vertx-mqtt,io.vertx.mqtt.test.server.MqttServerClientPublishTest.publishQos0,java.util.concurrent.TimeoutException,
extended,vertx-mqtt,io.vertx.mqtt.test.server.MqttServerUnsubscribeTest.unsubscribe,java.util.concurrent.TimeoutException,
vert-x3.vertx-rabbitmq-client_output,vertx-rabbitmq-client,io.vertx.rabbitmq.RabbitMQConsumptionStreamingTest.pauseAndResumeShouldWork,java.util.concurrent.ExecutionException,* Multiple error messages. *
vert-x3.vertx-rabbitmq-client_output,vertx-rabbitmq-client,io.vertx.rabbitmq.RabbitMQServiceTest.testMessageOrderingWhenConsumingNewApi,java.util.concurrent.ExecutionException,* Multiple error messages. *
vert-x3.vertx-rabbitmq-client_output,vertx-rabbitmq-client,io.vertx.rabbitmq.RabbitMQClientReconnectTest.testReconnect,java.util.concurrent.ExecutionException,* Multiple error messages. *
vert-x3.vertx-rabbitmq-client_output,vertx-rabbitmq-client,io.vertx.rabbitmq.RabbitMQServiceTest.testBasicConsume,java.util.concurrent.ExecutionException,* Multiple error messages. *
extended,vertexium-accumulo,org.vertexium.accumulo.AccumuloGraphTest.testFindPathsMultiplePaths,java.lang.RuntimeException, Failed to start Accumulo mini cluster\\n
extended,vertexium-core,org.vertexium.util.IncreasingTimeTest.currentTimeMillisReturnsTimeGreaterThanSystemTime,java.lang.AssertionError,
extended,vertexium-inmemory,org.vertexium.inmemory.InMemoryGraphTest.testMarkPropertyVisible,java.lang.AssertionError, expected:<0> but was:<1>\\n
extended,admiral-adapter-registry,com.vmware.admiral.adapter.registry.service.RegistryAdapterServiceProxyTest.testInitNoProxyWithList,java.lang.RuntimeException, java.util.concurrent.TimeoutException: Failed to check replicated service availability\\n
extended,admiral-adapter-registry,com.vmware.admiral.adapter.registry.service.RegistryAdapterServiceProxyTest.testWithProxyWithList,java.lang.RuntimeException, java.util.concurrent.TimeoutException: Failed to check replicated service availability\\n
extended,admiral-adapter-registry,com.vmware.admiral.adapter.registry.service.RegistryAdapterServiceProxyTest.testInitNoProxyNoList,java.lang.RuntimeException, java.util.concurrent.TimeoutException: Failed to check replicated service availability\\n
extended,admiral-compute,com.vmware.admiral.compute.cluster.ClusterServiceTest.testPatchSingleHostClusterWithPublicAddress,java.lang.AssertionError, expected:<test-address> but was:<null>\\n
extended,admiral-request,com.vmware.admiral.request.ServiceDocumentDeleteTaskServiceTest.testDeleteEventsWithGroups,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.ReservationRemovalTaskServiceTest.testReservationRemovalTaskLife,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.util.LongURIGetServiceTest.testBadRequest,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.VolumesFromAffinityHostFilterTest.testProvisionContainerWhenAnotherAlreadyProvisionedAndHasVolumesFromRules,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.NamedVolumeAffinityHostFilterTest.testFailWhenLocalVolumesShared2,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.ContainerToNetworkAffinityHostFilterTest.testFilterHostsWhenACoupleOfClustersAvailable,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.ContainerRemovalTaskServiceTest.testRemoveOfStaleContainerOperationFromHostRemoval,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.ClusterServiceLinkAffinityHostFilterTest.testSelectHostExistingContainerWithoutLink,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.VolumesFromAffinityHostFilterTest.testSelectContainerHostVolumesFromContainersReadOnlyIndication,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.ReservationTaskServiceTest.testReservationTaskLifeCycleWithMemoryLimitInRange,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.ServiceAntiAffinityHostFilterTest.testMoreThanOneContainersWithDifferentHostsInAffinity,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.ReservationTaskServiceTest.testDeploymentPoliciesOnMultipleHostsAndPlacements,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.NamedVolumeAffinityHostFilterTest.testFilterHostsWhenLocalDriverIsNotReported,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.ContainerHostRemovalTaskServiceTest.testRequestBrokerContainerHostRemovalWithKubernetesResources,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.ContainerClusteringTaskServiceTest.testContainerClusteringTaskAddContainersServiceRemove,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.ContainerClusteringTaskServiceTest.testContainerClusteringTaskServiceAddContainers,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.ReservationTaskServiceTest.testReservationTaskLifeCycleWithNoGroup,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.ClusterServiceLinkAffinityHostFilterTest.testSelectHostExistingContainerWithLinkNoAlias,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.BinpackAffinityHostFilterTest.testFilterBasedOnMaxLoadedHost,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.NamedVolumeAffinityHostFilterTest.testFilterDoesNotAffectHosts,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.pks.PKSClusterProvisioningTaskServiceTest.testDoValidatePlanSelection,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.ClusterLocalAffinityHostFilterTest.testFilterWithLocalNonNamedVolumes,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.allocation.filter.ClusterLocalAffinityHostFilterTest.testFilterWithLocalNamedVolumes,java.lang.RuntimeException, java.util.concurrent.CancellationException: host is stopping\\n
extended,admiral-request,com.vmware.admiral.request.ContainerControlLoopServiceTest.redeploymentOfSingleContainers,com.vmware.xenon.common.ServiceHost$ServiceAlreadyStartedException, Service already started: /config/migration stage: CREATED
extended,Wikidata-Toolkit-wdtk-dumpfiles,org.wikidata.wdtk.dumpfiles.MwDumpFileProcessingTest.testMwMostRecentFullDumpFileProcessing,java.io.IOException," Cannot write to ""/home/awshi2/Wikidata/Wikidata-Toolkit"" since we are in read-only mode.\\n"
extended,Wikidata-Toolkit-wdtk-dumpfiles,org.wikidata.wdtk.dumpfiles.MwDumpFileProcessingTest.testMwDailyDumpFileProcessing,java.io.IOException," Cannot write to ""/home/awshi2/Wikidata/Wikidata-Toolkit"" since we are in read-only mode.\\n"
extended,Wikidata-Toolkit-wdtk-util,org.wikidata.wdtk.util.DirectoryManagerFactoryTest.createDefaultDirectoryManagerPath,java.lang.RuntimeException, java.lang.NoSuchMethodException: org.wikidata.wdtk.util.DirectoryManagerFactoryTest$TestDirectoryManager.<init>(java.nio.file.Path; java.lang.Boolean)\\n
extended,Wikidata-Toolkit-wdtk-util,org.wikidata.wdtk.util.DirectoryManagerFactoryTest.createDirectoryManagerIoException,java.lang.Exception, Unexpected exception; expected<java.io.IOException> but was<java.lang.RuntimeException>\\n
extended,carbon-apimgt-analyzer-modules-org.wso2.carbon.apimgt.throttling.siddhi.extension,org.wso2.carbon.apimgt.throttling.siddhi.extension.ThrottleTimeBatchWindowTestCase.throttleTimeWindowBatchTest1,java.lang.AssertionError, expected:<2> but was:<1>\\n
extended,carbon-apimgt-components-apimgt-org.wso2.carbon.apimgt.core,org.wso2.carbon.apimgt.core.auth.ScopeRegistrationServiceStubFactoryTest.testGetScopeRegistration,java.lang.AssertionError,
extended,riptide-riptide-backup,org.zalando.riptide.backup.BackupRequestPluginTest.shouldUseBackupRequest,java.util.concurrent.TimeoutException,
extended,riptide-riptide-failsafe,org.zalando.riptide.failsafe.RetryAfterDelayFunctionTest.shouldRetryOnDemandWithDynamicDelay,org.junit.runners.model.TestTimedOutException, test timed out after 1500 milliseconds\\n
extended,riptide-riptide-spring-boot-starter,org.zalando.riptide.spring.AccessTokensDefaultCredentialsDirectoryTest.shouldUseCredentialsDirectory,org.zalando.stups.tokens.CredentialsUnavailableException, /home/awshi2/zalando/riptide/src/test/resources/client.json (No such file or directory)\\n
